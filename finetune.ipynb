{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection and Recognition Training Pipeline\n",
    "\n",
    "This pipeline outlines the overall steps for training and using a face recognition model:\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Preparation](#1-import-libraries)\n",
    "2. [Image Preprocessing (Face Detection and Cropping)](#2-face-detection)\n",
    "3. [InceptionResnetV1 Model Initialization](#3-inceptionresnetv1)\n",
    "4. [Model Training (Fine-tuning)](#4-fine-tuning)\n",
    "5. [Testing and Inference](#5-inference-and-testing)\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "1. **[Data Preparation](#1-import-libraries)**: Face image data is organized in a specific directory structure, with each subdirectory representing an identity (person).\n",
    "\n",
    "2. **[Image Preprocessing (Face Detection and Cropping)](#2-face-detection)**:\n",
    "   * The MTCNN (Multi-task Cascaded Convolutional Networks) model is used to detect faces in each image.\n",
    "   * Detected faces are cropped and aligned to a standard size (160x160 pixels), then saved to a new directory. This step ensures that only faces are fed into training, removing noise from the surrounding environment.\n",
    "\n",
    "3. **[InceptionResnetV1 Model Initialization](#3-inceptionresnetv1)**:\n",
    "   * An InceptionResnetV1 model is initialized. This model is initially trained on a large dataset (such as VGGFace2) and then fine-tuned for the specific number of classes (people) in your dataset.\n",
    "\n",
    "4. **[Model Training (Fine-tuning)](#4-fine-tuning)**:\n",
    "   * The cropped and normalized face data is split into training and validation sets.\n",
    "   * The model is trained using Cross Entropy loss function and Adam optimizer.\n",
    "   * The training process runs through multiple epochs, with performance monitoring on both training and validation sets.\n",
    "   * After training, the model weights are saved.\n",
    "\n",
    "5. **[Testing and Inference](#5-inference-and-testing)**:\n",
    "   * The trained model is loaded back.\n",
    "   * When a new image arrives, MTCNN is again used to detect and crop the face.\n",
    "   * The cropped face is fed into the InceptionResnetV1 model to predict the identity and confidence of that prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\uit-bootcamp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Define run parameters\n",
    "\n",
    "The dataset should follow the VGGFace2/ImageNet-style directory layout. Modify `data_dir` to the location of the dataset on wish to finetune on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Dataset/raw'\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 8\n",
    "workers = 0 if os.name == 'nt' else 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. TODO 1: Function dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_info(data_dir):\n",
    "    \"\"\"Print dataset information including number of classes and images per class\n",
    "    TODO 1\n",
    "    Args:\n",
    "        data_dir (str): Path to the dataset directory (e.g., 'Dataset/raw')\n",
    "    \n",
    "    Expected Output:\n",
    "        Should print information about the dataset in this format:\n",
    "        \n",
    "        Dataset Information for: Dataset/raw\n",
    "        ==================================================\n",
    "        Number of classes: 2\n",
    "        Classes: ['vanhau', 'vantoan']\n",
    "        \n",
    "        Images per class:\n",
    "        ------------------------------\n",
    "          vanhau: 15 images\n",
    "            Examples: OIP (1).jpg, OIP (2).jpg, OIP (3).jpg\n",
    "            ... and 12 more\n",
    "        \n",
    "          vantoan: 12 images\n",
    "            Examples: OIP (1).jpg, image1.jpg, image2.jpg\n",
    "            ... and 9 more\n",
    "        \n",
    "        Total images in dataset: 27\n",
    "        ==================================================\n",
    "    \n",
    "    Requirements:\n",
    "        1. Check if the data_dir exists, if not print error message\n",
    "        2. Find all subdirectories (these represent classes/people)\n",
    "        3. Count total number of classes\n",
    "        4. For each class, count how many image files (.jpg, .jpeg, .png, .bmp, .gif)\n",
    "        5. Show first 3 image names as examples for each class\n",
    "        6. Calculate and display total images across all classes\n",
    "        7. Handle edge cases (empty directories, no classes found)\n",
    "    \n",
    "    Hints:\n",
    "        - Use os.path.exists() to check if directory exists\n",
    "        - Use os.listdir() to get directory contents\n",
    "        - Use os.path.isdir() to check if item is a directory\n",
    "        - Use str.lower().endswith() to check file extensions\n",
    "        - Use len() to count items\n",
    "        - Use sorted() to display classes in alphabetical order\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Test the function with your dataset\n",
    "dataset_info('Dataset/raw')\n",
    "\n",
    "# def dataset_info(data_dir):\n",
    "#     \"\"\"Print dataset information including number of classes and images per class\"\"\"\n",
    "#     # Step 1: Check if directory exists\n",
    "#     if not os.path.exists(data_dir):\n",
    "#         print(f\"Error: Dataset directory '{data_dir}' not found.\")\n",
    "#         return\n",
    "    \n",
    "#     # Step 2: Find all subdirectories (classes)\n",
    "#     items = os.listdir(data_dir)\n",
    "#     classes = []\n",
    "#     for item in items:\n",
    "#         item_path = os.path.join(data_dir, item)\n",
    "#         if os.path.isdir(item_path):\n",
    "#             classes.append(item)\n",
    "    \n",
    "#     # Step 3: Handle no classes found\n",
    "#     if not classes:\n",
    "#         print(f\"No class directories found in '{data_dir}'\")\n",
    "#         return\n",
    "    \n",
    "#     # Sort classes alphabetically\n",
    "#     classes = sorted(classes)\n",
    "    \n",
    "#     # Step 4: Print header information\n",
    "#     print(f\"Dataset Information for: {data_dir}\")\n",
    "#     print(\"=\" * 50)\n",
    "#     print(f\"Number of classes: {len(classes)}\")\n",
    "#     print(f\"Classes: {classes}\")\n",
    "#     print()\n",
    "#     print(\"Images per class:\")\n",
    "#     print(\"-\" * 30)\n",
    "    \n",
    "#     # Step 5: Count images in each class\n",
    "#     total_images = 0\n",
    "#     image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
    "    \n",
    "#     for class_name in classes:\n",
    "#         class_path = os.path.join(data_dir, class_name)\n",
    "        \n",
    "#         # Get all files in class directory\n",
    "#         files = os.listdir(class_path)\n",
    "        \n",
    "#         # Filter only image files\n",
    "#         images = []\n",
    "#         for file in files:\n",
    "#             if file.lower().endswith(image_extensions):\n",
    "#                 images.append(file)\n",
    "        \n",
    "#         num_images = len(images)\n",
    "#         total_images += num_images\n",
    "        \n",
    "#         # Print class information\n",
    "#         print(f\"  {class_name}: {num_images} images\")\n",
    "        \n",
    "#         # Show examples if images exist\n",
    "#         if num_images > 0:\n",
    "#             examples = images[:3]  # First 3 images\n",
    "#             print(f\"    Examples: {', '.join(examples)}\")\n",
    "#             if num_images > 3:\n",
    "#                 print(f\"    ... and {num_images - 3} more\")\n",
    "#         print()\n",
    "    \n",
    "#     # Step 6: Print total\n",
    "#     print(f\"Total images in dataset: {total_images}\")\n",
    "#     print(\"=\" * 50)\n",
    "    \n",
    "# dataset_info('Dataset/raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 of 1"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
    "dataset.samples = [\n",
    "    (p, p.replace(data_dir, data_dir + '_cropped'))\n",
    "        for p, _ in dataset.samples\n",
    "]\n",
    "        \n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=training.collate_pil\n",
    ")\n",
    "\n",
    "for i, (x, y) in enumerate(loader):\n",
    "    mtcnn(x, save_path=y)\n",
    "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
    "    \n",
    "# Remove mtcnn to reduce GPU memory usage\n",
    "del mtcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. InceptionResNetV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(\n",
    "    classify=True,\n",
    "    pretrained='vggface2',\n",
    "    num_classes=len(dataset.class_to_idx)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Setup Optimizer, Scheduler, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "scheduler = MultiStepLR(optimizer, [5, 10])\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "dataset = datasets.ImageFolder(data_dir + '_cropped', transform=trans)\n",
    "img_inds = np.arange(len(dataset))\n",
    "np.random.shuffle(img_inds)\n",
    "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
    "val_inds = img_inds[int(0.8 * len(img_inds)):]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(train_inds)\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(val_inds)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. TODO 2: The Accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing pseudo_accuracy function...\n",
      "==================================================\n",
      "❌ Function pseudo_accuracy() returns None - not implemented yet!\n",
      "Please implement the function according to the TODO instructions.\n"
     ]
    }
   ],
   "source": [
    "def pseudo_accuracy(outputs, targets):\n",
    "    \"\"\"\n",
    "    TODO 2\n",
    "    Calculate accuracy using simple math operations (for educational purposes)\n",
    "    \n",
    "    Args:\n",
    "        outputs: Model predictions (tensor with shape [batch_size, num_classes])\n",
    "        targets: True labels (tensor with shape [batch_size])\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: Float value between 0 and 1\n",
    "    \n",
    "    Example:\n",
    "        If we have 4 samples with predictions and true labels:\n",
    "        outputs = [[0.1, 0.9], [0.8, 0.2], [0.3, 0.7], [0.6, 0.4]]  # 2 classes\n",
    "        targets = [1, 0, 1, 0]  # true labels\n",
    "        \n",
    "        Step 1: Find predicted class (highest value index)\n",
    "        predicted = [1, 0, 1, 0]  # [0.9>0.1, 0.8>0.2, 0.7>0.3, 0.6>0.4]\n",
    "        \n",
    "        Step 2: Compare with true labels\n",
    "        correct = [True, True, True, True]  # all predictions match targets\n",
    "        \n",
    "        Step 3: Calculate accuracy\n",
    "        accuracy = 4/4 = 1.0 (100% correct)\n",
    "    \n",
    "    Your task:\n",
    "        1. Convert PyTorch tensors to Python lists\n",
    "        2. Find the predicted class for each sample (index of maximum value)\n",
    "        3. Compare predictions with true labels\n",
    "        4. Count correct predictions\n",
    "        5. Calculate accuracy = correct_count / total_count\n",
    "    \n",
    "    Hints:\n",
    "        - Use .tolist() to convert tensor to Python list\n",
    "        - Use max() and list.index() to find the index of maximum value\n",
    "        - Use sum() to count True values in a boolean list\n",
    "        - Use len() to get total number of samples\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# def pseudo_accuracy(outputs, targets):\n",
    "#     \"\"\"Calculate accuracy using simple math operations (for educational purposes)\"\"\"\n",
    "#     # Step 1: Convert PyTorch tensors to Python lists\n",
    "#     outputs_list = outputs.tolist()\n",
    "#     targets_list = targets.tolist()\n",
    "    \n",
    "#     # Step 2: Find predicted class for each sample (index of maximum value)\n",
    "#     predicted_classes = []\n",
    "#     for output_row in outputs_list:\n",
    "#         # Find the index of maximum value\n",
    "#         max_value = max(output_row)\n",
    "#         predicted_class = output_row.index(max_value)\n",
    "#         predicted_classes.append(predicted_class)\n",
    "    \n",
    "#     # Step 3: Compare predictions with true labels\n",
    "#     correct_predictions = []\n",
    "#     for i in range(len(predicted_classes)):\n",
    "#         is_correct = predicted_classes[i] == targets_list[i]\n",
    "#         correct_predictions.append(is_correct)\n",
    "    \n",
    "#     # Step 4: Count correct predictions\n",
    "#     correct_count = sum(correct_predictions)  # sum() counts True as 1, False as 0\n",
    "    \n",
    "#     # Step 5: Calculate accuracy\n",
    "#     total_count = len(targets_list)\n",
    "#     accuracy = correct_count / total_count\n",
    "    \n",
    "#     return torch.tensor(accuracy)\n",
    "\n",
    "\n",
    "def test_pseudo_accuracy():\n",
    "    \"\"\"Test function to verify pseudo_accuracy implementation\"\"\"\n",
    "    print(\"Testing pseudo_accuracy function...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if pseudo_accuracy is implemented\n",
    "    try:\n",
    "        # Try a simple test first to see if function is implemented\n",
    "        test_outputs = torch.tensor([[0.1, 0.9]], dtype=torch.float32)\n",
    "        test_targets = torch.tensor([1], dtype=torch.long)\n",
    "        test_result = pseudo_accuracy(test_outputs, test_targets)\n",
    "        \n",
    "        # If we get here, function is implemented but might return None\n",
    "        if test_result is None:\n",
    "            print(\"❌ Function pseudo_accuracy() returns None - not implemented yet!\")\n",
    "            print(\"Please implement the function according to the TODO instructions.\")\n",
    "            return\n",
    "            \n",
    "    except (NotImplementedError, TypeError, AttributeError):\n",
    "        print(\"❌ Function pseudo_accuracy() is not implemented yet!\")\n",
    "        print(\"Please implement the function according to the TODO instructions.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in pseudo_accuracy() implementation: {str(e)}\")\n",
    "        print(\"Please check your implementation and try again.\")\n",
    "        return\n",
    "    \n",
    "    print(\"✅ Function pseudo_accuracy() is implemented! Running tests...\")\n",
    "    print()\n",
    "    \n",
    "    # Test case 1: Perfect accuracy\n",
    "    # Simulating outputs for 2-class problem\n",
    "    outputs_list = [\n",
    "        [0.1, 0.9],  # predicted class 1, target should be 1\n",
    "        [0.8, 0.2],  # predicted class 0, target should be 0  \n",
    "        [0.3, 0.7],  # predicted class 1, target should be 1\n",
    "        [0.9, 0.1]   # predicted class 0, target should be 0\n",
    "    ]\n",
    "    targets_list = [1, 0, 1, 0]\n",
    "    \n",
    "    # Convert to tensors (simulating PyTorch tensors)\n",
    "    outputs_tensor = torch.tensor(outputs_list, dtype=torch.float32)\n",
    "    targets_tensor = torch.tensor(targets_list, dtype=torch.long)\n",
    "    \n",
    "    try:\n",
    "        # Test your function\n",
    "        accuracy = pseudo_accuracy(outputs_tensor, targets_tensor)\n",
    "        expected_accuracy = 1.0  # 100% correct\n",
    "        \n",
    "        print(f\"Test Case 1 - Perfect Accuracy:\")\n",
    "        print(f\"Outputs: {outputs_list}\")\n",
    "        print(f\"Targets: {targets_list}\")\n",
    "        print(f\"Your result: {accuracy}\")\n",
    "        print(f\"Expected: {expected_accuracy}\")\n",
    "        \n",
    "        # Handle different return types\n",
    "        if accuracy is None:\n",
    "            print(f\"Status: ❌ FAIL - Function returns None\")\n",
    "        elif isinstance(accuracy, (int, float, torch.Tensor)):\n",
    "            # Convert tensor to float for comparison\n",
    "            acc_value = float(accuracy) if isinstance(accuracy, torch.Tensor) else accuracy\n",
    "            status = \"✅ PASS\" if abs(acc_value - expected_accuracy) < 0.001 else \"❌ FAIL\"\n",
    "            print(f\"Status: {status}\")\n",
    "        else:\n",
    "            print(f\"Status: ❌ FAIL - Unexpected return type: {type(accuracy)}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Test Case 1 - Error: {str(e)}\")\n",
    "        print(\"❌ FAIL - Exception occurred during test\")\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "    # Test case 2: 50% accuracy\n",
    "    outputs_list_2 = [\n",
    "        [0.8, 0.2],  # predicted class 0, target is 1 (wrong)\n",
    "        [0.1, 0.9],  # predicted class 1, target is 1 (correct)\n",
    "        [0.6, 0.4],  # predicted class 0, target is 1 (wrong) \n",
    "        [0.3, 0.7]   # predicted class 1, target is 1 (correct)\n",
    "    ]\n",
    "    targets_list_2 = [1, 1, 1, 1]\n",
    "    \n",
    "    outputs_tensor_2 = torch.tensor(outputs_list_2, dtype=torch.float32)\n",
    "    targets_tensor_2 = torch.tensor(targets_list_2, dtype=torch.long)\n",
    "    \n",
    "    try:\n",
    "        accuracy_2 = pseudo_accuracy(outputs_tensor_2, targets_tensor_2)\n",
    "        expected_accuracy_2 = 0.5  # 50% correct (2 out of 4)\n",
    "        \n",
    "        print(f\"Test Case 2 - 50% Accuracy:\")\n",
    "        print(f\"Outputs: {outputs_list_2}\")\n",
    "        print(f\"Targets: {targets_list_2}\")\n",
    "        print(f\"Your result: {accuracy_2}\")\n",
    "        print(f\"Expected: {expected_accuracy_2}\")\n",
    "        \n",
    "        # Handle different return types\n",
    "        if accuracy_2 is None:\n",
    "            print(f\"Status: ❌ FAIL - Function returns None\")\n",
    "        elif isinstance(accuracy_2, (int, float, torch.Tensor)):\n",
    "            # Convert tensor to float for comparison\n",
    "            acc_value_2 = float(accuracy_2) if isinstance(accuracy_2, torch.Tensor) else accuracy_2\n",
    "            status = \"✅ PASS\" if abs(acc_value_2 - expected_accuracy_2) < 0.001 else \"❌ FAIL\"\n",
    "            print(f\"Status: {status}\")\n",
    "        else:\n",
    "            print(f\"Status: ❌ FAIL - Unexpected return type: {type(accuracy_2)}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Test Case 2 - Error: {str(e)}\")\n",
    "        print(\"❌ FAIL - Exception occurred during test\")\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "    # Compare with PyTorch's built-in accuracy (only if both tests passed)\n",
    "    try:\n",
    "        if accuracy is not None and accuracy_2 is not None:\n",
    "            pytorch_acc_1 = training.accuracy(outputs_tensor, targets_tensor)\n",
    "            pytorch_acc_2 = training.accuracy(outputs_tensor_2, targets_tensor_2)\n",
    "            \n",
    "            print(f\"Comparison with PyTorch built-in accuracy:\")\n",
    "            print(f\"Test 1 - Your: {accuracy}, PyTorch: {pytorch_acc_1}\")\n",
    "            print(f\"Test 2 - Your: {accuracy_2}, PyTorch: {pytorch_acc_2}\")\n",
    "            \n",
    "            # Convert to float for comparison\n",
    "            acc_1_val = float(accuracy) if isinstance(accuracy, torch.Tensor) else accuracy\n",
    "            acc_2_val = float(accuracy_2) if isinstance(accuracy_2, torch.Tensor) else accuracy_2\n",
    "            pytorch_1_val = float(pytorch_acc_1)\n",
    "            pytorch_2_val = float(pytorch_acc_2)\n",
    "            \n",
    "            if (abs(acc_1_val - pytorch_1_val) < 0.001 and \n",
    "                abs(acc_2_val - pytorch_2_val) < 0.001):\n",
    "                print(\"🎉 Your implementation matches PyTorch's accuracy!\")\n",
    "            else:\n",
    "                print(\"❌ Your implementation doesn't match PyTorch's accuracy.\")\n",
    "                print(\"Please check your logic and try again.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing with PyTorch accuracy: {str(e)}\")\n",
    "\n",
    "# Test the pseudo_accuracy function with error handling\n",
    "test_pseudo_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy metrics above were merely our educational pseudo-implementation—a delightful learning exercise! Now, let us embrace the **official, battle-tested accuracy** that the pros use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\n",
    "    'fps': training.BatchTimer(),\n",
    "    'acc': training.accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Initial\n",
      "----------\n",
      "Valid |     1/1    | loss:    0.6379 | fps:   18.5233 | acc:    0.5000   \n",
      "\n",
      "Epoch 1/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.7728 | fps:    9.0614 | acc:    0.6000   \n",
      "Valid |     1/1    | loss:    0.1957 | fps:   20.9738 | acc:    1.0000   \n",
      "\n",
      "Epoch 2/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.1837 | fps:    9.5596 | acc:    0.9333   \n",
      "Valid |     1/1    | loss:   22.0069 | fps:   24.8276 | acc:    0.5000   \n",
      "\n",
      "Epoch 3/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.3759 | fps:   11.0099 | acc:    0.8667   \n",
      "Valid |     1/1    | loss:   94.0064 | fps:   25.0130 | acc:    0.5000   \n",
      "\n",
      "Epoch 4/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.0022 | fps:    9.4539 | acc:    1.0000   \n",
      "Valid |     1/1    | loss:  122.8393 | fps:   17.0070 | acc:    0.5000   \n",
      "\n",
      "Epoch 5/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.0571 | fps:   11.3488 | acc:    0.9333   \n",
      "Valid |     1/1    | loss:  120.2414 | fps:   24.9019 | acc:    0.5000   \n",
      "\n",
      "Epoch 6/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.3177 | fps:   11.3508 | acc:    0.9333   \n",
      "Valid |     1/1    | loss:   33.0355 | fps:   19.5145 | acc:    0.5000   \n",
      "\n",
      "Epoch 7/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.2254 | fps:   10.9710 | acc:    0.9333   \n",
      "Valid |     1/1    | loss:   13.2348 | fps:   24.7496 | acc:    0.5000   \n",
      "\n",
      "Epoch 8/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.0513 | fps:   10.8133 | acc:    0.9333   \n",
      "Valid |     1/1    | loss:    6.3540 | fps:   24.4380 | acc:    0.5000   \n",
      "\n",
      "Model saved to: facenet_vantoan_vanhau.pth\n",
      "Class names saved to: class_names.txt\n",
      "Classes: ['vanhau', 'vantoan']\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.iteration, writer.interval = 0, 10\n",
    "\n",
    "print('\\n\\nInitial')\n",
    "print('-' * 10)\n",
    "resnet.eval()\n",
    "training.pass_epoch(\n",
    "    resnet, loss_fn, val_loader,\n",
    "    batch_metrics=metrics, show_running=True, device=device,\n",
    "    writer=writer\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    resnet.train()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "    resnet.eval()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, val_loader,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# Save the trained model after training completes\n",
    "model_save_path = 'facenet_vantoan_vanhau.pth'\n",
    "torch.save(resnet.state_dict(), model_save_path)\n",
    "print(f'\\nModel saved to: {model_save_path}')\n",
    "\n",
    "# Save class names for inference\n",
    "class_names_save_path = 'class_names.txt'\n",
    "with open(class_names_save_path, 'w') as f:\n",
    "    for class_name in dataset.classes:\n",
    "        f.write(f\"{class_name}\\n\")\n",
    "print(f'Class names saved to: {class_names_save_path}')\n",
    "print(f'Classes: {dataset.classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference and Testing\n",
    "Test the trained model on sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded class names from file: ['vanhau', 'vantoan']\n",
      "Model loaded successfully for inference.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load trained model for inference\n",
    "def load_trained_model(model_path, num_classes, device):\n",
    "    model = InceptionResnetV1(\n",
    "        classify=True,\n",
    "        pretrained='vggface2',\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Initialize MTCNN for inference\n",
    "mtcnn_inference = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Load class names with error handling\n",
    "class_names_path = 'class_names.txt'\n",
    "model_path = 'facenet_vantoan_vanhau.pth'\n",
    "\n",
    "try:\n",
    "    # Try to load class names from file\n",
    "    with open(class_names_path, 'r') as f:\n",
    "        class_names = [line.strip() for line in f.readlines()]\n",
    "    print(f\"Loaded class names from file: {class_names}\")\n",
    "except FileNotFoundError:\n",
    "    # Fallback: use current dataset classes\n",
    "    try:\n",
    "        class_names = dataset.classes\n",
    "        print(f\"Using current dataset classes: {class_names}\")\n",
    "    except NameError:\n",
    "        print(\"Error: No dataset or class names file found. Please run training first.\")\n",
    "        class_names = []\n",
    "\n",
    "# Load trained model with error handling\n",
    "if class_names and os.path.exists(model_path):\n",
    "    try:\n",
    "        model_inference = load_trained_model(model_path, len(class_names), device)\n",
    "        print(f\"Model loaded successfully for inference.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        model_inference = None\n",
    "else:\n",
    "    if not class_names:\n",
    "        print(\"Cannot load model: No class names available.\")\n",
    "    else:\n",
    "        print(f\"Cannot load model: Model file not found at {model_path}\")\n",
    "        print(\"Please run the training cells first to create the model.\")\n",
    "    model_inference = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing predict_image function...\n",
      "==================================================\n",
      "❌ Function predict_image() returns None - not implemented yet!\n",
      "Please implement the function according to the TODO instructions.\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model, mtcnn, class_names, device):\n",
    "    \"\"\"\n",
    "    TODO 3\n",
    "    Predict class of face in image using trained model\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        model: Trained InceptionResnetV1 model\n",
    "        mtcnn: MTCNN face detection model\n",
    "        class_names (list): List of class names\n",
    "        device: PyTorch device (CPU or CUDA)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (predicted_class, confidence_score)\n",
    "               - predicted_class (str): Name of predicted class or error message\n",
    "               - confidence_score (float): Confidence score between 0 and 1\n",
    "    \n",
    "    Example:\n",
    "        If input image contains a face of \"vanhau\" class:\n",
    "        return (\"vanhau\", 0.95)\n",
    "        \n",
    "        If no face detected:\n",
    "        return (\"No face detected\", 0.0)\n",
    "        \n",
    "        If error occurs:\n",
    "        return (\"Error: description\", 0.0)\n",
    "    \n",
    "    Your task:\n",
    "        1. Load and convert image to RGB\n",
    "        2. Use MTCNN to detect and crop face from image\n",
    "        3. Check if face was detected, return appropriate message if not\n",
    "        4. Preprocess the cropped face for model input\n",
    "        5. Run inference with the trained model\n",
    "        6. Apply softmax to get probabilities\n",
    "        7. Find the class with highest probability\n",
    "        8. Return predicted class name and confidence score\n",
    "        9. Handle any exceptions that might occur\n",
    "    \n",
    "    Hints:\n",
    "        - Use Image.open(image_path).convert('RGB') to load image\n",
    "        - Use mtcnn(img) to detect and crop face\n",
    "        - Use img_cropped.unsqueeze(0).to(device) to add batch dimension\n",
    "        - Use torch.no_grad() context for inference\n",
    "        - Use torch.nn.functional.softmax(outputs, dim=1) for probabilities\n",
    "        - Use torch.max(probabilities, 1) to get max probability and index\n",
    "        - Use predicted.item() to get class index, then class_names[index] for name\n",
    "        - Use try-except to handle errors gracefully\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# def predict_image(image_path, model, mtcnn, class_names, device):\n",
    "#     \"\"\"Predict class of face in image\"\"\"\n",
    "#     try:\n",
    "#         # Step 1: Load and convert image to RGB\n",
    "#         img = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "#         # Step 2: Use MTCNN to detect and crop face\n",
    "#         img_cropped = mtcnn(img)\n",
    "        \n",
    "#         # Step 3: Check if face was detected\n",
    "#         if img_cropped is None:\n",
    "#             return \"No face detected\", 0.0\n",
    "        \n",
    "#         # Step 4: Preprocess for model input (add batch dimension and move to device)\n",
    "#         img_cropped = img_cropped.unsqueeze(0).to(device)\n",
    "        \n",
    "#         # Step 5: Run inference with trained model\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(img_cropped)\n",
    "            \n",
    "#             # Step 6: Apply softmax to get probabilities\n",
    "#             probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            \n",
    "#             # Step 7: Find class with highest probability\n",
    "#             confidence, predicted = torch.max(probabilities, 1)\n",
    "        \n",
    "#         # Step 8: Get predicted class name and confidence score\n",
    "#         predicted_class = class_names[predicted.item()]\n",
    "#         confidence_score = confidence.item()\n",
    "        \n",
    "#         return predicted_class, confidence_score\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         # Step 9: Handle exceptions gracefully\n",
    "#         return f\"Error: {str(e)}\", 0.0\n",
    "\n",
    "\n",
    "def test_predict_image():\n",
    "    \"\"\"Test function to verify predict_image implementation\"\"\"\n",
    "    print(\"Testing predict_image function...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if predict_image is implemented\n",
    "    try:\n",
    "        # Create dummy inputs for testing\n",
    "        test_image_path = \"dummy_path.jpg\"  # This will cause an error, which is expected for testing\n",
    "        dummy_model = None\n",
    "        dummy_mtcnn = None\n",
    "        dummy_class_names = [\"class1\", \"class2\"]\n",
    "        dummy_device = torch.device('cpu')\n",
    "        \n",
    "        test_result = predict_image(test_image_path, dummy_model, dummy_mtcnn, dummy_class_names, dummy_device)\n",
    "        \n",
    "        # If we get here, function is implemented but might return None\n",
    "        if test_result is None:\n",
    "            print(\"❌ Function predict_image() returns None - not implemented yet!\")\n",
    "            print(\"Please implement the function according to the TODO instructions.\")\n",
    "            return\n",
    "        \n",
    "        # Check if it returns a tuple with 2 elements\n",
    "        if not isinstance(test_result, tuple) or len(test_result) != 2:\n",
    "            print(\"❌ Function should return a tuple with 2 elements: (predicted_class, confidence)\")\n",
    "            print(\"Please check your implementation.\")\n",
    "            return\n",
    "            \n",
    "    except (NotImplementedError, TypeError, AttributeError):\n",
    "        print(\"❌ Function predict_image() is not implemented yet!\")\n",
    "        print(\"Please implement the function according to the TODO instructions.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        # This is expected since we're using dummy inputs\n",
    "        if \"dummy_path.jpg\" in str(e) or \"NoneType\" in str(e):\n",
    "            print(\"✅ Function predict_image() is implemented! (Error handling works correctly)\")\n",
    "            print(\"Function correctly handles invalid inputs and returns error messages.\")\n",
    "        else:\n",
    "            print(f\"❌ Unexpected error in predict_image() implementation: {str(e)}\")\n",
    "            print(\"Please check your implementation and try again.\")\n",
    "            return\n",
    "    \n",
    "    print(\"\\n🎉 predict_image() function structure is correct!\")\n",
    "    print(\"💡 To fully test this function, you need:\")\n",
    "    print(\"   1. A trained model loaded\")\n",
    "    print(\"   2. MTCNN initialized\") \n",
    "    print(\"   3. Valid image files\")\n",
    "    print(\"   4. Class names list\")\n",
    "    print(\"\\nOnce training is complete, this function will be tested automatically.\")\n",
    "\n",
    "# Test the predict_image function\n",
    "test_predict_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model on sample images...\n",
      "==================================================\n",
      "❌ Function predict_image() is not implemented yet!\n",
      "Please implement the predict_image() function according to the TODO 3 instructions.\n"
     ]
    }
   ],
   "source": [
    "def test_sample_images():\n",
    "    \"\"\"Test model on sample images from both classes\"\"\"\n",
    "    # Check if predict_image function is implemented first\n",
    "    try:\n",
    "        # Test with dummy inputs to see if function is implemented\n",
    "        dummy_result = predict_image(\"dummy.jpg\", None, None, [\"test\"], torch.device('cpu'))\n",
    "        \n",
    "        # If we get here and result is None, function is not implemented\n",
    "        if dummy_result is None:\n",
    "            print(\"❌ Function predict_image() is not implemented yet!\")\n",
    "            print(\"Please implement the predict_image() function according to the TODO 3 instructions.\")\n",
    "            return []\n",
    "            \n",
    "    except (NotImplementedError, TypeError, AttributeError):\n",
    "        print(\"❌ Function predict_image() is not implemented yet!\")\n",
    "        print(\"Please implement the predict_image() function according to the TODO 3 instructions.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        # This is expected for dummy inputs - function is implemented\n",
    "        pass\n",
    "    \n",
    "    # Check if model and class names are available\n",
    "    if model_inference is None:\n",
    "        print(\"Error: Model not loaded. Cannot run inference.\")\n",
    "        return []\n",
    "    \n",
    "    if not class_names:\n",
    "        print(\"Error: No class names available.\")\n",
    "        return []\n",
    "    \n",
    "    print(\"✅ predict_image() function is implemented! Running tests...\")\n",
    "    print()\n",
    "    \n",
    "    test_results = []\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        if os.path.exists(class_dir):\n",
    "            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            if not images:\n",
    "                print(f\"No images found in {class_dir}\")\n",
    "                continue\n",
    "            \n",
    "            # Test first few images from each class\n",
    "            for img_file in images[:3]:\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                predicted_class, confidence = predict_image(\n",
    "                    img_path, model_inference, mtcnn_inference, class_names, device\n",
    "                )\n",
    "                \n",
    "                result = {\n",
    "                    'true_class': class_name,\n",
    "                    'predicted_class': predicted_class,\n",
    "                    'confidence': confidence,\n",
    "                    'correct': predicted_class == class_name,\n",
    "                    'image_path': img_path\n",
    "                }\n",
    "                test_results.append(result)\n",
    "                \n",
    "                status = \"✅\" if result['correct'] else \"❌\"\n",
    "                print(f\"{status} {class_name} -> {predicted_class} (conf: {confidence:.3f})\")\n",
    "        else:\n",
    "            print(f\"Directory not found: {class_dir}\")\n",
    "    \n",
    "    # Summary\n",
    "    if test_results:\n",
    "        correct_predictions = sum(1 for r in test_results if r['correct'])\n",
    "        accuracy = correct_predictions / len(test_results)\n",
    "        print(f\"\\nTest Results: {correct_predictions}/{len(test_results)} correct ({accuracy*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"No test results available.\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# Run tests with comprehensive error handling\n",
    "print(\"Testing model on sample images...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check all prerequisites\n",
    "if model_inference is not None and class_names:\n",
    "    test_results = test_sample_images()\n",
    "else:\n",
    "    print(\"Cannot run tests: Model or class names not available.\")\n",
    "    print(\"Please ensure training has completed successfully.\")\n",
    "    print()\n",
    "    \n",
    "    # Also check if predict_image is implemented\n",
    "    try:\n",
    "        dummy_result = predict_image(\"dummy.jpg\", None, None, [\"test\"], torch.device('cpu'))\n",
    "        if dummy_result is None:\n",
    "            print(\"Additionally: predict_image() function is not implemented.\")\n",
    "    except (NotImplementedError, TypeError, AttributeError):\n",
    "        print(\"Additionally: predict_image() function is not implemented.\")\n",
    "    except:\n",
    "        print(\"predict_image() function appears to be implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uit-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
