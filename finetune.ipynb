{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection and Recognition Training Pipeline\n",
    "\n",
    "This pipeline outlines the overall steps for training and using a face recognition model:\n",
    "\n",
    "## 0.1. Table of Contents\n",
    "1. [Data Preparation](#1-import-libraries)\n",
    "2. [Image Preprocessing (Face Detection and Cropping)](#2-face-detection)\n",
    "3. [InceptionResnetV1 Model Initialization](#3-inceptionresnetv1)\n",
    "4. [Model Training (Fine-tuning)](#4-fine-tuning)\n",
    "5. [Testing and Inference](#5-inference-and-testing)\n",
    "6. [TODO List](#6-todo-list)\n",
    "\n",
    "## 0.2. Pipeline Overview\n",
    "\n",
    "1. **[Data Preparation](#1-import-libraries)**: Face image data is organized in a specific directory structure, with each subdirectory representing an identity (person).\n",
    "\n",
    "2. **[Image Preprocessing (Face Detection and Cropping)](#2-face-detection)**:\n",
    "   * The MTCNN (Multi-task Cascaded Convolutional Networks) model is used to detect faces in each image.\n",
    "   * Detected faces are cropped and aligned to a standard size (160x160 pixels), then saved to a new directory. This step ensures that only faces are fed into training, removing noise from the surrounding environment.\n",
    "\n",
    "3. **[InceptionResnetV1 Model Initialization](#3-inceptionresnetv1)**:\n",
    "   * An InceptionResnetV1 model is initialized. This model is initially trained on a large dataset (such as VGGFace2) and then fine-tuned for the specific number of classes (people) in your dataset.\n",
    "\n",
    "4. **[Model Training (Fine-tuning)](#4-fine-tuning)**:\n",
    "   * The cropped and normalized face data is split into training and validation sets.\n",
    "   * The model is trained using Cross Entropy loss function and Adam optimizer.\n",
    "   * The training process runs through multiple epochs, with performance monitoring on both training and validation sets.\n",
    "   * After training, the model weights are saved.\n",
    "\n",
    "5. **[Testing and Inference](#5-inference-and-testing)**:\n",
    "   * The trained model is loaded back.\n",
    "   * When a new image arrives, MTCNN is again used to detect and crop the face.\n",
    "   * The cropped face is fed into the InceptionResnetV1 model to predict the identity and confidence of that prediction.\n",
    "\n",
    "## 0.3. TODO List\n",
    "\n",
    "### üìã Implementation Tasks (4 TODOs to Complete)\n",
    "\n",
    "#### 0.3.1. TODO 1: Dataset Information Function\n",
    "**Location:** Section 1.2  \n",
    "**Function:** `dataset_info(data_dir)`  \n",
    "**Status:** ‚ùå Not Implemented  \n",
    "**Priority:** High  \n",
    "\n",
    "#### 0.3.2. TODO 2: Image Rotation Function\n",
    "**Location:** Section 1.3  \n",
    "**Function:** `rotate_image_180(image)`  \n",
    "**Status:** ‚ùå Not Implemented  \n",
    "**Priority:** Medium  \n",
    "\n",
    "#### 0.3.3. TODO 3: Custom Accuracy Function\n",
    "**Location:** Section 3.3  \n",
    "**Function:** `custom_accuracy(outputs, targets)`  \n",
    "**Status:** ‚ùå Not Implemented  \n",
    "**Priority:** High  \n",
    "\n",
    "#### 0.3.4. TODO 4: Custom Softmax Function\n",
    "**Location:** Section 5.1  \n",
    "**Function:** `custom_softmax(logits)`  \n",
    "**Status:** ‚ùå Not Implemented  \n",
    "**Priority:** High  \n",
    "\n",
    "### üß™ Test Functions with Assertions\n",
    "\n",
    "Each TODO has comprehensive test functions with assertions:\n",
    "\n",
    "#### Test Functions Available:\n",
    "1. **`test_rotation_function()`** - Tests TODO 2 with assertions\n",
    "2. **`test_custom_accuracy()`** - Tests TODO 3 with assertions  \n",
    "3. **`test_custom_softmax()`** - Tests TODO 4 with assertions\n",
    "4. **Edge case tests** for each function\n",
    "\n",
    "#### Test Features:\n",
    "- ‚úÖ **Assertion-based validation** (no print statements)\n",
    "- ‚úÖ **Error handling and debugging**\n",
    "- ‚úÖ **Comparison with PyTorch implementations**\n",
    "- ‚úÖ **Edge case coverage**\n",
    "- ‚úÖ **Mathematical correctness verification**\n",
    "\n",
    "### üìù Implementation Order Recommendation:\n",
    "\n",
    "1. **Start with TODO 1** (Dataset Info) - Essential for understanding your data\n",
    "2. **Implement TODO 3** (Custom Accuracy) - Core ML metric needed for training\n",
    "3. **Complete TODO 4** (Custom Softmax) - Required for inference\n",
    "4. **Finish with TODO 2** (Image Rotation) - Data augmentation enhancement\n",
    "\n",
    "### üéØ Success Criteria:\n",
    "\n",
    "- All test functions pass with assertions\n",
    "- Functions match PyTorch implementations (where applicable)\n",
    "- Code handles edge cases gracefully\n",
    "- Mathematical properties are preserved\n",
    "- Educational value is maintained (step-by-step implementations)\n",
    "\n",
    "### üí° Getting Started:\n",
    "\n",
    "1. Run the test functions to see current status\n",
    "2. Implement functions one by one\n",
    "3. Use the comprehensive assert-based tests to verify correctness\n",
    "4. Refer to the mathematical formulas and examples provided\n",
    "5. Test edge cases thoroughly before moving to the next TODO\n",
    "\n",
    "**Note:** All test functions use assertions for rigorous validation. This ensures your implementations are mathematically correct and robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\uit-bootcamp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Define run parameters\n",
    "\n",
    "The dataset should follow the VGGFace2/ImageNet-style directory layout. Modify `data_dir` to the location of the dataset on wish to finetune on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Dataset/raw'\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 8\n",
    "workers = 0 if os.name == 'nt' else 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. TODO 1: Function dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_info(data_dir):\n",
    "    \"\"\"Print dataset information including number of classes and images per class\n",
    "    TODO 1\n",
    "    Args:\n",
    "        data_dir (str): Path to the dataset directory (e.g., 'Dataset/raw')\n",
    "    \n",
    "    Expected Output:\n",
    "        Should print information about the dataset in this format:\n",
    "        \n",
    "        Dataset Information for: Dataset/raw\n",
    "        ==================================================\n",
    "        Number of classes: 2\n",
    "        Classes: ['vanhau', 'vantoan']\n",
    "        \n",
    "        Images per class:\n",
    "        ------------------------------\n",
    "          vanhau: 15 images\n",
    "            Examples: OIP (1).jpg, OIP (2).jpg, OIP (3).jpg\n",
    "            ... and 12 more\n",
    "        \n",
    "          vantoan: 12 images\n",
    "            Examples: OIP (1).jpg, image1.jpg, image2.jpg\n",
    "            ... and 9 more\n",
    "        \n",
    "        Total images in dataset: 27\n",
    "        ==================================================\n",
    "    \n",
    "    Requirements:\n",
    "        1. Check if the data_dir exists, if not print error message\n",
    "        2. Find all subdirectories (these represent classes/people)\n",
    "        3. Count total number of classes\n",
    "        4. For each class, count how many image files (.jpg, .jpeg, .png, .bmp, .gif)\n",
    "        5. Show first 3 image names as examples for each class\n",
    "        6. Calculate and display total images across all classes\n",
    "        7. Handle edge cases (empty directories, no classes found)\n",
    "    \n",
    "    Hints:\n",
    "        - Use os.path.exists() to check if directory exists\n",
    "        - Use os.listdir() to get directory contents\n",
    "        - Use os.path.isdir() to check if item is a directory\n",
    "        - Use str.lower().endswith() to check file extensions\n",
    "        - Use len() to count items\n",
    "        - Use sorted() to display classes in alphabetical order\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Test the function with your dataset\n",
    "dataset_info('Dataset/raw')\n",
    "\n",
    "# def dataset_info(data_dir):\n",
    "#     \"\"\"Print dataset information including number of classes and images per class\"\"\"\n",
    "#     # Step 1: Check if directory exists\n",
    "#     if not os.path.exists(data_dir):\n",
    "#         print(f\"Error: Dataset directory '{data_dir}' not found.\")\n",
    "#         return\n",
    "    \n",
    "#     # Step 2: Find all subdirectories (classes)\n",
    "#     items = os.listdir(data_dir)\n",
    "#     classes = []\n",
    "#     for item in items:\n",
    "#         item_path = os.path.join(data_dir, item)\n",
    "#         if os.path.isdir(item_path):\n",
    "#             classes.append(item)\n",
    "    \n",
    "#     # Step 3: Handle no classes found\n",
    "#     if not classes:\n",
    "#         print(f\"No class directories found in '{data_dir}'\")\n",
    "#         return\n",
    "    \n",
    "#     # Sort classes alphabetically\n",
    "#     classes = sorted(classes)\n",
    "    \n",
    "#     # Step 4: Print header information\n",
    "#     print(f\"Dataset Information for: {data_dir}\")\n",
    "#     print(\"=\" * 50)\n",
    "#     print(f\"Number of classes: {len(classes)}\")\n",
    "#     print(f\"Classes: {classes}\")\n",
    "#     print()\n",
    "#     print(\"Images per class:\")\n",
    "#     print(\"-\" * 30)\n",
    "    \n",
    "#     # Step 5: Count images in each class\n",
    "#     total_images = 0\n",
    "#     image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
    "    \n",
    "#     for class_name in classes:\n",
    "#         class_path = os.path.join(data_dir, class_name)\n",
    "        \n",
    "#         # Get all files in class directory\n",
    "#         files = os.listdir(class_path)\n",
    "        \n",
    "#         # Filter only image files\n",
    "#         images = []\n",
    "#         for file in files:\n",
    "#             if file.lower().endswith(image_extensions):\n",
    "#                 images.append(file)\n",
    "        \n",
    "#         num_images = len(images)\n",
    "#         total_images += num_images\n",
    "        \n",
    "#         # Print class information\n",
    "#         print(f\"  {class_name}: {num_images} images\")\n",
    "        \n",
    "#         # Show examples if images exist\n",
    "#         if num_images > 0:\n",
    "#             examples = images[:3]  # First 3 images\n",
    "#             print(f\"    Examples: {', '.join(examples)}\")\n",
    "#             if num_images > 3:\n",
    "#                 print(f\"    ... and {num_images - 3} more\")\n",
    "#         print()\n",
    "    \n",
    "#     # Step 6: Print total\n",
    "#     print(f\"Total images in dataset: {total_images}\")\n",
    "#     print(\"=\" * 50)\n",
    "    \n",
    "# dataset_info('Dataset/raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. TODO 2: Augmentation - Rotate Image 180 Degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image_180(image):\n",
    "    \"\"\"\n",
    "    TODO 2\n",
    "    Rotate an image 180 degrees using only NumPy operations (for educational purposes)\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image with shape (height, width, channels) or (height, width)\n",
    "                              Image values should be in range [0, 255] for uint8 or [0, 1] for float\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Rotated image with same shape and data type as input\n",
    "    \n",
    "    Mathematical Concept:\n",
    "        Rotating 180 degrees is equivalent to:\n",
    "        - Flipping vertically (top-bottom) AND horizontally (left-right)\n",
    "        - OR reversing both height and width dimensions\n",
    "        \n",
    "        For pixel at position (row, col):\n",
    "        new_position = (height-1-row, width-1-col)\n",
    "    \n",
    "    Example:\n",
    "        Original:     Rotated 180¬∞:\n",
    "        [1, 2, 3]  ‚Üí  [9, 8, 7]\n",
    "        [4, 5, 6]  ‚Üí  [6, 5, 4] \n",
    "        [7, 8, 9]  ‚Üí  [3, 2, 1]\n",
    "    \n",
    "    Your task:\n",
    "        1. Get image dimensions (height, width)\n",
    "        2. Create a new array with same shape and data type\n",
    "        3. For each pixel, calculate its new position after 180¬∞ rotation\n",
    "        4. Copy pixel values to new positions\n",
    "        5. Return the rotated image\n",
    "    \n",
    "    Hints:\n",
    "        - Use image.shape to get dimensions\n",
    "        - Use np.zeros_like() to create array with same shape and dtype\n",
    "        - Use nested loops or NumPy indexing to copy pixels\n",
    "        - Remember: new_row = height - 1 - old_row\n",
    "        - Remember: new_col = width - 1 - old_col\n",
    "        - Handle both grayscale (2D) and color (3D) images\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# def rotate_image_180(image):\n",
    "#     import numpy as np\n",
    "    \n",
    "#     # Method 1: Using nested loops (educational approach)\n",
    "#     # Get image dimensions\n",
    "#     if len(image.shape) == 2:  # Grayscale image\n",
    "#         height, width = image.shape\n",
    "#         rotated = np.zeros_like(image)\n",
    "        \n",
    "#         # Rotate each pixel\n",
    "#         for row in range(height):\n",
    "#             for col in range(width):\n",
    "#                 new_row = height - 1 - row\n",
    "#                 new_col = width - 1 - col\n",
    "#                 rotated[new_row, new_col] = image[row, col]\n",
    "                \n",
    "#     elif len(image.shape) == 3:  # Color image\n",
    "#         height, width, channels = image.shape\n",
    "#         rotated = np.zeros_like(image)\n",
    "        \n",
    "#         # Rotate each pixel for all channels\n",
    "#         for row in range(height):\n",
    "#             for col in range(width):\n",
    "#                 new_row = height - 1 - row\n",
    "#                 new_col = width - 1 - col\n",
    "#                 rotated[new_row, new_col] = image[row, col]\n",
    "#     else:\n",
    "#         raise ValueError(\"Image must be 2D (grayscale) or 3D (color)\")\n",
    "    \n",
    "#     return rotated\n",
    "\n",
    "# def rotate_image_180_optimized(image):\n",
    "#     \"\"\"\n",
    "#     Optimized version using NumPy slicing (bonus implementation)\n",
    "#     This is more efficient but less educational\n",
    "#     \"\"\"\n",
    "#     import numpy as np\n",
    "    \n",
    "#     # Method 2: Using NumPy slicing (more efficient)\n",
    "#     # Flip both dimensions: [::-1] reverses the array along that axis\n",
    "#     if len(image.shape) == 2:  # Grayscale\n",
    "#         return image[::-1, ::-1]\n",
    "#     elif len(image.shape) == 3:  # Color\n",
    "#         return image[::-1, ::-1, :]\n",
    "#     else:\n",
    "#         raise ValueError(\"Image must be 2D (grayscale) or 3D (color)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing image rotation function with assertions...\n",
      "==================================================\n",
      "Test Case 1 - 3x3 Grayscale Image:\n",
      "Original:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "Rotated (Manual Implementation):\n",
      "None\n",
      "‚ùå Test Case 1: FAILED - Function returned None - not implemented yet!\n",
      "Please implement the rotate_image_180() function.\n",
      "\n",
      "Testing edge cases...\n",
      "==============================\n",
      "‚ùå Edge case test FAILED: Single pixel should remain unchanged\n",
      "\n",
      "Demonstration with assertion-based verification:\n",
      "==================================================\n",
      "‚ùå Demonstration ERROR: 'NoneType' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "def test_rotation_function():\n",
    "    \"\"\"Test function to verify rotation implementation using assertions\"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"Testing image rotation function with assertions...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test Case 1: Simple 3x3 matrix\n",
    "    test_image = np.array([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ], dtype=np.uint8)\n",
    "    \n",
    "    expected_rotated = np.array([\n",
    "        [9, 8, 7],\n",
    "        [6, 5, 4],\n",
    "        [3, 2, 1]\n",
    "    ], dtype=np.uint8)\n",
    "    \n",
    "    print(\"Test Case 1 - 3x3 Grayscale Image:\")\n",
    "    print(\"Original:\")\n",
    "    print(test_image)\n",
    "    \n",
    "    try:\n",
    "        # Test manual implementation\n",
    "        rotated_manual = rotate_image_180(test_image)\n",
    "        print(\"\\nRotated (Manual Implementation):\")\n",
    "        print(rotated_manual)\n",
    "        \n",
    "        # Assert tests\n",
    "        assert rotated_manual is not None, \"Function returned None - not implemented yet!\"\n",
    "        assert isinstance(rotated_manual, np.ndarray), f\"Expected numpy array, got {type(rotated_manual)}\"\n",
    "        assert rotated_manual.shape == test_image.shape, f\"Shape mismatch: expected {test_image.shape}, got {rotated_manual.shape}\"\n",
    "        assert rotated_manual.dtype == test_image.dtype, f\"Data type mismatch: expected {test_image.dtype}, got {rotated_manual.dtype}\"\n",
    "        assert np.array_equal(rotated_manual, expected_rotated), \"Rotation result doesn't match expected output\"\n",
    "        \n",
    "        print(\"‚úÖ Test Case 1: PASSED - All assertions successful!\")\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå Test Case 1: FAILED - {str(e)}\")\n",
    "        if 'not implemented' in str(e):\n",
    "            print(\"Please implement the rotate_image_180() function.\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"Expected:\")\n",
    "            print(expected_rotated)\n",
    "            print(\"Got:\")\n",
    "            print(rotated_manual if 'rotated_manual' in locals() else \"No result\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test Case 1: ERROR - {str(e)}\")\n",
    "        print(\"Make sure you've implemented the rotate_image_180() function correctly.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    \n",
    "    # Test Case 2: Color image (3D array)\n",
    "    test_color = np.array([\n",
    "        [[255, 0, 0], [0, 255, 0]],     # Red, Green\n",
    "        [[0, 0, 255], [255, 255, 0]]    # Blue, Yellow\n",
    "    ], dtype=np.uint8)\n",
    "    \n",
    "    expected_color = np.array([\n",
    "        [[255, 255, 0], [0, 0, 255]],   # Yellow, Blue\n",
    "        [[0, 255, 0], [255, 0, 0]]      # Green, Red\n",
    "    ], dtype=np.uint8)\n",
    "    \n",
    "    print(\"Test Case 2 - 2x2 Color Image:\")\n",
    "    print(\"Original shape:\", test_color.shape)\n",
    "    print(\"Original layout:\")\n",
    "    print(\"  Position (0,0): Red(255,0,0)    Position (0,1): Green(0,255,0)\")\n",
    "    print(\"  Position (1,0): Blue(0,0,255)   Position (1,1): Yellow(255,255,0)\")\n",
    "    \n",
    "    try:\n",
    "        rotated_color = rotate_image_180(test_color)\n",
    "        print(f\"\\nRotated shape: {rotated_color.shape}\")\n",
    "        print(\"Expected layout after 180¬∞ rotation:\")\n",
    "        print(\"  Position (0,0): Yellow(255,255,0)  Position (0,1): Blue(0,0,255)\")\n",
    "        print(\"  Position (1,0): Green(0,255,0)     Position (1,1): Red(255,0,0)\")\n",
    "        \n",
    "        # Assert tests for color image\n",
    "        assert rotated_color is not None, \"Function returned None for color image\"\n",
    "        assert isinstance(rotated_color, np.ndarray), f\"Expected numpy array, got {type(rotated_color)}\"\n",
    "        assert rotated_color.shape == test_color.shape, f\"Shape mismatch: expected {test_color.shape}, got {rotated_color.shape}\"\n",
    "        assert rotated_color.dtype == test_color.dtype, f\"Data type mismatch: expected {test_color.dtype}, got {rotated_color.dtype}\"\n",
    "        assert len(rotated_color.shape) == 3, f\"Expected 3D array for color image, got {len(rotated_color.shape)}D\"\n",
    "        assert np.array_equal(rotated_color, expected_color), \"Color rotation result doesn't match expected output\"\n",
    "        \n",
    "        print(\"‚úÖ Test Case 2: PASSED - Color image rotation correct!\")\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå Test Case 2: FAILED - {str(e)}\")\n",
    "        print(\"Expected result:\")\n",
    "        print(expected_color)\n",
    "        print(\"Your result:\")\n",
    "        print(rotated_color if 'rotated_color' in locals() else \"No result\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test Case 2: ERROR - {str(e)}\")\n",
    "        print(\"Make sure your function handles 3D color images correctly.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüéâ ALL TESTS PASSED! Your rotation implementation is correct!\")\n",
    "\n",
    "# Test the rotation function\n",
    "test_rotation_function()\n",
    "\n",
    "def test_rotation_edge_cases():\n",
    "    \"\"\"Additional edge case tests with assertions\"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"\\nTesting edge cases...\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # Test Case 3: Single pixel\n",
    "        single_pixel = np.array([[42]], dtype=np.uint8)\n",
    "        rotated_single = rotate_image_180(single_pixel)\n",
    "        assert np.array_equal(rotated_single, single_pixel), \"Single pixel should remain unchanged\"\n",
    "        print(\"‚úÖ Single pixel test: PASSED\")\n",
    "        \n",
    "        # Test Case 4: 2x2 matrix\n",
    "        test_2x2 = np.array([\n",
    "            [1, 2],\n",
    "            [3, 4]\n",
    "        ], dtype=np.uint8)\n",
    "        expected_2x2 = np.array([\n",
    "            [4, 3],\n",
    "            [2, 1]\n",
    "        ], dtype=np.uint8)\n",
    "        rotated_2x2 = rotate_image_180(test_2x2)\n",
    "        assert np.array_equal(rotated_2x2, expected_2x2), \"2x2 rotation failed\"\n",
    "        print(\"‚úÖ 2x2 matrix test: PASSED\")\n",
    "        \n",
    "        # Test Case 5: Different data types\n",
    "        test_float = np.array([\n",
    "            [0.1, 0.2],\n",
    "            [0.3, 0.4]\n",
    "        ], dtype=np.float32)\n",
    "        expected_float = np.array([\n",
    "            [0.4, 0.3],\n",
    "            [0.2, 0.1]\n",
    "        ], dtype=np.float32)\n",
    "        rotated_float = rotate_image_180(test_float)\n",
    "        assert np.allclose(rotated_float, expected_float), \"Float array rotation failed\"\n",
    "        assert rotated_float.dtype == test_float.dtype, \"Data type not preserved\"\n",
    "        print(\"‚úÖ Float array test: PASSED\")\n",
    "        \n",
    "        print(\"\\nüéâ ALL EDGE CASE TESTS PASSED!\")\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå Edge case test FAILED: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Edge case test ERROR: {str(e)}\")\n",
    "\n",
    "# Run edge case tests\n",
    "test_rotation_edge_cases()\n",
    "\n",
    "def demonstrate_rotation_with_assertions():\n",
    "    \"\"\"Demonstrate rotation with assertion-based verification\"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"\\nDemonstration with assertion-based verification:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Create test pattern\n",
    "        height, width = 100, 100\n",
    "        test_pattern = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Create diagonal stripes\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                if (i + j) % 20 < 10:\n",
    "                    test_pattern[i, j] = [255, 0, 0]  # Red\n",
    "                else:\n",
    "                    test_pattern[i, j] = [0, 0, 255]  # Blue\n",
    "        \n",
    "        # Add white square in top-left corner\n",
    "        test_pattern[10:30, 10:30] = [255, 255, 255]\n",
    "        \n",
    "        # Rotate the pattern\n",
    "        rotated_pattern = rotate_image_180(test_pattern)\n",
    "        \n",
    "        # Assertions for verification\n",
    "        assert rotated_pattern.shape == test_pattern.shape, \"Shape should be preserved\"\n",
    "        assert rotated_pattern.dtype == test_pattern.dtype, \"Data type should be preserved\"\n",
    "        \n",
    "        # Verify white square moved from top-left to bottom-right\n",
    "        original_white = np.all(test_pattern[10:30, 10:30] == [255, 255, 255], axis=2)\n",
    "        rotated_white = np.all(rotated_pattern[70:90, 70:90] == [255, 255, 255], axis=2)\n",
    "        \n",
    "        assert np.all(original_white), \"Original white square not found in expected position\"\n",
    "        assert np.all(rotated_white), \"Rotated white square not found in expected position\"\n",
    "        \n",
    "        # Verify corners are swapped correctly\n",
    "        assert np.array_equal(test_pattern[0, 0], rotated_pattern[99, 99]), \"Top-left to bottom-right swap failed\"\n",
    "        assert np.array_equal(test_pattern[99, 99], rotated_pattern[0, 0]), \"Bottom-right to top-left swap failed\"\n",
    "        assert np.array_equal(test_pattern[0, 99], rotated_pattern[99, 0]), \"Top-right to bottom-left swap failed\"\n",
    "        assert np.array_equal(test_pattern[99, 0], rotated_pattern[0, 99]), \"Bottom-left to top-right swap failed\"\n",
    "        \n",
    "        print(\"‚úÖ Pattern creation and rotation: SUCCESS\")\n",
    "        print(\"‚úÖ White square position verification: SUCCESS\")\n",
    "        print(\"‚úÖ Corner pixel verification: SUCCESS\")\n",
    "        print(\"üéâ All demonstration assertions PASSED!\")\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå Demonstration FAILED: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Demonstration ERROR: {str(e)}\")\n",
    "\n",
    "# Run demonstration with assertions\n",
    "demonstrate_rotation_with_assertions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation180:\n",
    "    \"\"\"Custom transform to randomly rotate images 180 degrees\"\"\"\n",
    "    def __init__(self, probability=0.5):\n",
    "        self.probability = probability\n",
    "        # Check once if custom function is available\n",
    "        self.use_custom = self._check_custom_function()\n",
    "    \n",
    "    def _check_custom_function(self):\n",
    "        \"\"\"Check if rotate_image_180 is implemented and working\"\"\"\n",
    "        try:\n",
    "            test_array = np.array([[1, 2], [3, 4]], dtype=np.uint8)\n",
    "            result = rotate_image_180(test_array)\n",
    "            return result is not None and isinstance(result, np.ndarray)\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.probability:\n",
    "            if self.use_custom:\n",
    "                # Use custom implementation\n",
    "                try:\n",
    "                    if hasattr(img, 'mode'):  # PIL Image\n",
    "                        img_array = np.array(img)\n",
    "                        rotated = rotate_image_180(img_array)\n",
    "                        return Image.fromarray(rotated)\n",
    "                    else:  # numpy array\n",
    "                        return rotate_image_180(img)\n",
    "                except:\n",
    "                    # Fallback if custom function fails\n",
    "                    pass\n",
    "            \n",
    "            # Use built-in rotation (fallback)\n",
    "            if hasattr(img, 'mode'):  # PIL Image\n",
    "                return img.rotate(180)\n",
    "            else:  # numpy array\n",
    "                if len(img.shape) == 2:  # Grayscale\n",
    "                    return img[::-1, ::-1]\n",
    "                elif len(img.shape) == 3:  # Color\n",
    "                    return img[::-1, ::-1, :]\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 of 1"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
    "dataset.samples = [\n",
    "    (p, p.replace(data_dir, data_dir + '_cropped'))\n",
    "        for p, _ in dataset.samples\n",
    "]\n",
    "        \n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=training.collate_pil\n",
    ")\n",
    "\n",
    "for i, (x, y) in enumerate(loader):\n",
    "    mtcnn(x, save_path=y)\n",
    "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
    "    \n",
    "# Remove mtcnn to reduce GPU memory usage\n",
    "del mtcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. InceptionResNetV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(\n",
    "    classify=True,\n",
    "    pretrained='vggface2',\n",
    "    num_classes=len(dataset.class_to_idx)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Setup Optimizer, Scheduler, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "scheduler = MultiStepLR(optimizer, [5, 10])\n",
    "\n",
    "# Update transform to include both resize and rotation augmentation\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # Resize nh∆∞ b·∫°n ƒë√£ c√≥\n",
    "    RandomRotation180(probability=0.3),  # 30% chance to rotate 180 degrees\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir + '_cropped', transform=trans)\n",
    "img_inds = np.arange(len(dataset))\n",
    "np.random.shuffle(img_inds)\n",
    "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
    "val_inds = img_inds[int(0.8 * len(img_inds)):]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(train_inds)\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(val_inds)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. TODO 3: The Accuracy metric\n",
    "#### Understanding Accuracy Calculation - Mathematical Formula\n",
    "\n",
    "**Accuracy** is a fundamental metric in machine learning that measures the proportion of correct predictions.\n",
    "\n",
    "#### Mathematical Formula:\n",
    "\n",
    "```\n",
    "accuracy = (number of correct predictions) / (total number of predictions)\n",
    "\n",
    "accuracy = (1/N) √ó Œ£(i=1 to N) [≈∑·µ¢ == y·µ¢]\n",
    "\n",
    "where:\n",
    "- N = total number of samples\n",
    "- ≈∑·µ¢ = predicted class for sample i\n",
    "- y·µ¢ = true class for sample i\n",
    "- [condition] = indicator function (1 if true, 0 if false)\n",
    "```\n",
    "\n",
    "#### Step-by-Step Mathematical Process:\n",
    "\n",
    "1. **Get Predicted Classes:**\n",
    "   ```\n",
    "   ≈∑·µ¢ = argmax(output·µ¢)\n",
    "   where output·µ¢ = [p‚ÇÅ, p‚ÇÇ, ..., p‚Çñ] (model probabilities for k classes)\n",
    "   ```\n",
    "\n",
    "2. **Compare Predictions:**\n",
    "   ```\n",
    "   correct·µ¢ = {1 if ≈∑·µ¢ == y·µ¢\n",
    "              {0 if ≈∑·µ¢ ‚â† y·µ¢\n",
    "   ```\n",
    "\n",
    "3. **Calculate Final Accuracy:**\n",
    "   ```\n",
    "   accuracy = (Œ£ correct·µ¢) / N = (correct_count) / N\n",
    "   ```\n",
    "\n",
    "#### Example:\n",
    "```\n",
    "Given: outputs = [[0.1,0.9], [0.8,0.2], [0.3,0.7], [0.6,0.4]]\n",
    "       targets = [1, 0, 1, 0]\n",
    "\n",
    "Step 1: ≈∑ = [argmax([0.1,0.9]), argmax([0.8,0.2]), argmax([0.3,0.7]), argmax([0.6,0.4])]\n",
    "        ≈∑ = [1, 0, 1, 0]\n",
    "\n",
    "Step 2: correct = [1==1, 0==0, 1==1, 0==0] = [1, 1, 1, 1]\n",
    "\n",
    "Step 3: accuracy = (1+1+1+1)/4 = 4/4 = 1.0 = 100%\n",
    "```\n",
    "\n",
    "**Range:** accuracy ‚àà [0, 1] where 0 = 0% correct, 1 = 100% correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_accuracy(outputs, targets):\n",
    "    \"\"\"\n",
    "    TODO 3\n",
    "    Calculate accuracy using simple math operations (for educational purposes)\n",
    "    \n",
    "    Args:\n",
    "        outputs: Model predictions (tensor with shape [batch_size, num_classes])\n",
    "        targets: True labels (tensor with shape [batch_size])\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: Float value between 0 and 1\n",
    "    \n",
    "    Example:\n",
    "        If we have 4 samples with predictions and true labels:\n",
    "        outputs = [[0.1, 0.9], [0.8, 0.2], [0.3, 0.7], [0.6, 0.4]]  # 2 classes\n",
    "        targets = [1, 0, 1, 0]  # true labels\n",
    "        \n",
    "        Step 1: Find predicted class (highest value index)\n",
    "        predicted = [1, 0, 1, 0]  # [0.9>0.1, 0.8>0.2, 0.7>0.3, 0.6>0.4]\n",
    "        \n",
    "        Step 2: Compare with true labels\n",
    "        correct = [True, True, True, True]  # all predictions match targets\n",
    "        \n",
    "        Step 3: Calculate accuracy\n",
    "        accuracy = 4/4 = 1.0 (100% correct)\n",
    "    \n",
    "    Your task:\n",
    "        1. Convert PyTorch tensors to Python lists\n",
    "        2. Find the predicted class for each sample (index of maximum value)\n",
    "        3. Compare predictions with true labels\n",
    "        4. Count correct predictions\n",
    "        5. Calculate accuracy = correct_count / total_count\n",
    "    \n",
    "    Hints:\n",
    "        - Use .tolist() to convert tensor to Python list\n",
    "        - Use max() and list.index() to find the index of maximum value\n",
    "        - Use sum() to count True values in a boolean list\n",
    "        - Use len() to get total number of samples\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# def custom_accuracy(outputs, targets):\n",
    "#     \"\"\"Calculate accuracy using simple math operations (for educational purposes)\"\"\"\n",
    "#     # Step 1: Convert PyTorch tensors to Python lists\n",
    "#     outputs_list = outputs.tolist()\n",
    "#     targets_list = targets.tolist()\n",
    "    \n",
    "#     # Step 2: Find predicted class for each sample (index of maximum value)\n",
    "#     predicted_classes = []\n",
    "#     for output_row in outputs_list:\n",
    "#         # Find the index of maximum value\n",
    "#         max_value = max(output_row)\n",
    "#         predicted_class = output_row.index(max_value)\n",
    "#         predicted_classes.append(predicted_class)\n",
    "    \n",
    "#     # Step 3: Compare predictions with true labels\n",
    "#     correct_predictions = []\n",
    "#     for i in range(len(predicted_classes)):\n",
    "#         is_correct = predicted_classes[i] == targets_list[i]\n",
    "#         correct_predictions.append(is_correct)\n",
    "    \n",
    "#     # Step 4: Count correct predictions\n",
    "#     correct_count = sum(correct_predictions)  # sum() counts True as 1, False as 0\n",
    "    \n",
    "#     # Step 5: Calculate accuracy\n",
    "#     total_count = len(targets_list)\n",
    "#     accuracy = correct_count / total_count\n",
    "    \n",
    "#     return torch.tensor(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the function above :D xD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing custom_accuracy function with assertions...\n",
      "==================================================\n",
      "Test Case 1 - Perfect Accuracy:\n",
      "Outputs: [[0.1, 0.9], [0.8, 0.2], [0.3, 0.7], [0.9, 0.1]]\n",
      "Targets: [1, 0, 1, 0]\n",
      "Expected: 1.0\n",
      "Your result: None\n",
      "‚ùå Test Case 1: FAILED - Function returned None - not implemented yet!\n",
      "Please implement the custom_accuracy() function.\n",
      "\n",
      "Testing accuracy edge cases...\n",
      "==============================\n",
      "‚ùå Edge case test ERROR: unsupported operand type(s) for -: 'NoneType' and 'float'\n"
     ]
    }
   ],
   "source": [
    "def test_custom_accuracy():\n",
    "    \"\"\"Test function to verify custom_accuracy implementation using assertions\"\"\"\n",
    "    print(\"Testing custom_accuracy function with assertions...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test case 1: Perfect accuracy\n",
    "    outputs_list = [\n",
    "        [0.1, 0.9],  # predicted class 1, target should be 1\n",
    "        [0.8, 0.2],  # predicted class 0, target should be 0  \n",
    "        [0.3, 0.7],  # predicted class 1, target should be 1\n",
    "        [0.9, 0.1]   # predicted class 0, target should be 0\n",
    "    ]\n",
    "    targets_list = [1, 0, 1, 0]\n",
    "    expected_accuracy = 1.0  # 100% correct\n",
    "    \n",
    "    # Convert to tensors\n",
    "    outputs_tensor = torch.tensor(outputs_list, dtype=torch.float32)\n",
    "    targets_tensor = torch.tensor(targets_list, dtype=torch.long)\n",
    "    \n",
    "    print(\"Test Case 1 - Perfect Accuracy:\")\n",
    "    print(f\"Outputs: {outputs_list}\")\n",
    "    print(f\"Targets: {targets_list}\")\n",
    "    print(f\"Expected: {expected_accuracy}\")\n",
    "    \n",
    "    try:\n",
    "        # Test your function\n",
    "        accuracy = custom_accuracy(outputs_tensor, targets_tensor)\n",
    "        print(f\"Your result: {accuracy}\")\n",
    "        \n",
    "        # Assert tests\n",
    "        assert accuracy is not None, \"Function returned None - not implemented yet!\"\n",
    "        assert isinstance(accuracy, (int, float, torch.Tensor)), f\"Expected number or tensor, got {type(accuracy)}\"\n",
    "        \n",
    "        # Convert to float for comparison\n",
    "        acc_value = float(accuracy) if isinstance(accuracy, torch.Tensor) else accuracy\n",
    "        assert isinstance(acc_value, (int, float)), f\"Cannot convert result to float: {type(acc_value)}\"\n",
    "        assert 0.0 <= acc_value <= 1.0, f\"Accuracy should be between 0 and 1, got {acc_value}\"\n",
    "        assert abs(acc_value - expected_accuracy) < 0.001, f\"Expected {expected_accuracy}, got {acc_value}\"\n",
    "        \n",
    "        print(\"‚úÖ Test Case 1: PASSED - All assertions successful!\")\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå Test Case 1: FAILED - {str(e)}\")\n",
    "        if 'not implemented' in str(e):\n",
    "            print(\"Please implement the custom_accuracy() function.\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"Expected: {expected_accuracy}\")\n",
    "            print(f\"Got: {accuracy if 'accuracy' in locals() else 'No result'}\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test Case 1: ERROR - {str(e)}\")\n",
    "        print(\"Make sure you've implemented the custom_accuracy() function correctly.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    \n",
    "    # Test case 2: 50% accuracy\n",
    "    outputs_list_2 = [\n",
    "        [0.8, 0.2],  # predicted class 0, target is 1 (wrong)\n",
    "        [0.1, 0.9],  # predicted class 1, target is 1 (correct)\n",
    "        [0.6, 0.4],  # predicted class 0, target is 1 (wrong) \n",
    "        [0.3, 0.7]   # predicted class 1, target is 1 (correct)\n",
    "    ]\n",
    "    targets_list_2 = [1, 1, 1, 1]\n",
    "    expected_accuracy_2 = 0.5  # 50% correct (2 out of 4)\n",
    "    \n",
    "    outputs_tensor_2 = torch.tensor(outputs_list_2, dtype=torch.float32)\n",
    "    targets_tensor_2 = torch.tensor(targets_list_2, dtype=torch.long)\n",
    "    \n",
    "    print(\"Test Case 2 - 50% Accuracy:\")\n",
    "    print(f\"Outputs: {outputs_list_2}\")\n",
    "    print(f\"Targets: {targets_list_2}\")\n",
    "    print(f\"Expected: {expected_accuracy_2}\")\n",
    "    \n",
    "    try:\n",
    "        accuracy_2 = custom_accuracy(outputs_tensor_2, targets_tensor_2)\n",
    "        print(f\"Your result: {accuracy_2}\")\n",
    "        \n",
    "        # Assert tests for second case\n",
    "        assert accuracy_2 is not None, \"Function returned None for second test case\"\n",
    "        assert isinstance(accuracy_2, (int, float, torch.Tensor)), f\"Expected number or tensor, got {type(accuracy_2)}\"\n",
    "        \n",
    "        # Convert to float for comparison\n",
    "        acc_value_2 = float(accuracy_2) if isinstance(accuracy_2, torch.Tensor) else accuracy_2\n",
    "        assert isinstance(acc_value_2, (int, float)), f\"Cannot convert result to float: {type(acc_value_2)}\"\n",
    "        assert 0.0 <= acc_value_2 <= 1.0, f\"Accuracy should be between 0 and 1, got {acc_value_2}\"\n",
    "        assert abs(acc_value_2 - expected_accuracy_2) < 0.001, f\"Expected {expected_accuracy_2}, got {acc_value_2}\"\n",
    "        \n",
    "        print(\"‚úÖ Test Case 2: PASSED - 50% accuracy calculation correct!\")\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå Test Case 2: FAILED - {str(e)}\")\n",
    "        print(f\"Expected: {expected_accuracy_2}\")\n",
    "        print(f\"Got: {accuracy_2 if 'accuracy_2' in locals() else 'No result'}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test Case 2: ERROR - {str(e)}\")\n",
    "        print(\"Make sure your function handles different accuracy scenarios correctly.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    \n",
    "    # Test case 3: Compare with PyTorch's built-in accuracy\n",
    "    print(\"Test Case 3 - Comparison with PyTorch:\")\n",
    "    \n",
    "    try:\n",
    "        pytorch_acc_1 = training.accuracy(outputs_tensor, targets_tensor)\n",
    "        pytorch_acc_2 = training.accuracy(outputs_tensor_2, targets_tensor_2)\n",
    "        \n",
    "        print(f\"Test 1 - Your: {accuracy}, PyTorch: {pytorch_acc_1}\")\n",
    "        print(f\"Test 2 - Your: {accuracy_2}, PyTorch: {pytorch_acc_2}\")\n",
    "        \n",
    "        # Convert to float for comparison\n",
    "        acc_1_val = float(accuracy) if isinstance(accuracy, torch.Tensor) else accuracy\n",
    "        acc_2_val = float(accuracy_2) if isinstance(accuracy_2, torch.Tensor) else accuracy_2\n",
    "        pytorch_1_val = float(pytorch_acc_1)\n",
    "        pytorch_2_val = float(pytorch_acc_2)\n",
    "        \n",
    "        # Assert that our implementation matches PyTorch's\n",
    "        assert abs(acc_1_val - pytorch_1_val) < 0.001, f\"Test 1: Your {acc_1_val} != PyTorch {pytorch_1_val}\"\n",
    "        assert abs(acc_2_val - pytorch_2_val) < 0.001, f\"Test 2: Your {acc_2_val} != PyTorch {pytorch_2_val}\"\n",
    "        \n",
    "        print(\"‚úÖ Test Case 3: PASSED - Matches PyTorch accuracy!\")\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå Test Case 3: FAILED - {str(e)}\")\n",
    "        print(\"Your implementation doesn't match PyTorch's accuracy.\")\n",
    "        print(\"Please check your logic and try again.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test Case 3: ERROR - {str(e)}\")\n",
    "        print(\"Error comparing with PyTorch accuracy.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüéâ ALL TESTS PASSED! Your accuracy implementation is correct!\")\n",
    "\n",
    "# Test the custom_accuracy function with assertions\n",
    "test_custom_accuracy()\n",
    "\n",
    "def test_accuracy_edge_cases():\n",
    "    \"\"\"Additional edge case tests with assertions\"\"\"\n",
    "    print(\"\\nTesting accuracy edge cases...\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # Test Case 4: Zero accuracy (all wrong)\n",
    "        outputs_wrong = torch.tensor([\n",
    "            [0.9, 0.1],  # predicted 0, target 1 (wrong)\n",
    "            [0.8, 0.2],  # predicted 0, target 1 (wrong)\n",
    "        ], dtype=torch.float32)\n",
    "        targets_wrong = torch.tensor([1, 1], dtype=torch.long)\n",
    "        \n",
    "        accuracy_zero = custom_accuracy(outputs_wrong, targets_wrong)\n",
    "        acc_zero_val = float(accuracy_zero) if isinstance(accuracy_zero, torch.Tensor) else accuracy_zero\n",
    "        assert abs(acc_zero_val - 0.0) < 0.001, f\"Expected 0.0 accuracy, got {acc_zero_val}\"\n",
    "        print(\"‚úÖ Zero accuracy test: PASSED\")\n",
    "        \n",
    "        # Test Case 5: Single sample\n",
    "        outputs_single = torch.tensor([[0.2, 0.8]], dtype=torch.float32)\n",
    "        targets_single = torch.tensor([1], dtype=torch.long)\n",
    "        \n",
    "        accuracy_single = custom_accuracy(outputs_single, targets_single)\n",
    "        acc_single_val = float(accuracy_single) if isinstance(accuracy_single, torch.Tensor) else accuracy_single\n",
    "        assert abs(acc_single_val - 1.0) < 0.001, f\"Expected 1.0 accuracy, got {acc_single_val}\"\n",
    "        print(\"‚úÖ Single sample test: PASSED\")\n",
    "        \n",
    "        # Test Case 6: Multi-class (3 classes)\n",
    "        outputs_multi = torch.tensor([\n",
    "            [0.1, 0.2, 0.7],  # predicted class 2, target 2 (correct)\n",
    "            [0.8, 0.1, 0.1],  # predicted class 0, target 0 (correct)\n",
    "            [0.3, 0.6, 0.1],  # predicted class 1, target 1 (correct)\n",
    "        ], dtype=torch.float32)\n",
    "        targets_multi = torch.tensor([2, 0, 1], dtype=torch.long)\n",
    "        \n",
    "        accuracy_multi = custom_accuracy(outputs_multi, targets_multi)\n",
    "        acc_multi_val = float(accuracy_multi) if isinstance(accuracy_multi, torch.Tensor) else accuracy_multi\n",
    "        assert abs(acc_multi_val - 1.0) < 0.001, f\"Expected 1.0 accuracy for multi-class, got {acc_multi_val}\"\n",
    "        print(\"‚úÖ Multi-class test: PASSED\")\n",
    "        \n",
    "        print(\"\\nüéâ ALL EDGE CASE TESTS PASSED!\")\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå Edge case test FAILED: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Edge case test ERROR: {str(e)}\")\n",
    "\n",
    "# Run edge case tests\n",
    "test_accuracy_edge_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy metrics above were merely our educational pseudo-implementation‚Äîa delightful learning exercise! Now, let us embrace the **official, battle-tested accuracy** that the pros use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\n",
    "    'fps': training.BatchTimer(),\n",
    "    'acc': training.accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Initial\n",
      "----------\n",
      "Valid |     1/1    | loss:    0.6188 | fps:    2.8988 | acc:    0.7500   \n",
      "\n",
      "Epoch 1/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.6700 | fps:    0.9194 | acc:    0.5333   \n",
      "Valid |     1/1    | loss:    0.7857 | fps:    2.7260 | acc:    0.5000   \n",
      "\n",
      "Epoch 2/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.5873 | fps:    1.0631 | acc:    0.6667   \n",
      "Valid |     1/1    | loss:    2.0004 | fps:    2.9687 | acc:    0.7500   \n",
      "\n",
      "Epoch 3/8\n",
      "----------\n",
      "Train |     1/1    | loss:    1.1965 | fps:    1.1543 | acc:    0.6667   \n",
      "Valid |     1/1    | loss:    0.9899 | fps:    3.5241 | acc:    0.7500   \n",
      "\n",
      "Epoch 4/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.8660 | fps:    1.1095 | acc:    0.6667   \n",
      "Valid |     1/1    | loss:    5.1225 | fps:    3.3416 | acc:    0.2500   \n",
      "\n",
      "Epoch 5/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.3532 | fps:    1.2233 | acc:    0.8000   \n",
      "Valid |     1/1    | loss:   28.4749 | fps:    3.2688 | acc:    0.2500   \n",
      "\n",
      "Epoch 6/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.8424 | fps:    1.0378 | acc:    0.8667   \n",
      "Valid |     1/1    | loss:   15.4109 | fps:    2.3113 | acc:    0.2500   \n",
      "\n",
      "Epoch 7/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.2761 | fps:    0.9895 | acc:    0.8667   \n",
      "Valid |     1/1    | loss:   10.5551 | fps:    2.1973 | acc:    0.2500   \n",
      "\n",
      "Epoch 8/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.1240 | fps:    0.9400 | acc:    0.9333   \n",
      "Valid |     1/1    | loss:    8.2811 | fps:    2.7423 | acc:    0.2500   \n",
      "\n",
      "Model saved to: facenet_vantoan_vanhau.pth\n",
      "Class names saved to: class_names.txt\n",
      "Classes: ['vanhau', 'vantoan']\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.iteration, writer.interval = 0, 10\n",
    "\n",
    "print('\\n\\nInitial')\n",
    "print('-' * 10)\n",
    "resnet.eval()\n",
    "training.pass_epoch(\n",
    "    resnet, loss_fn, val_loader,\n",
    "    batch_metrics=metrics, show_running=True, device=device,\n",
    "    writer=writer\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    resnet.train()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "    resnet.eval()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, val_loader,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# Save the trained model after training completes\n",
    "model_save_path = 'facenet_vantoan_vanhau.pth'\n",
    "torch.save(resnet.state_dict(), model_save_path)\n",
    "print(f'\\nModel saved to: {model_save_path}')\n",
    "\n",
    "# Save class names for inference\n",
    "class_names_save_path = 'class_names.txt'\n",
    "with open(class_names_save_path, 'w') as f:\n",
    "    for class_name in dataset.classes:\n",
    "        f.write(f\"{class_name}\\n\")\n",
    "print(f'Class names saved to: {class_names_save_path}')\n",
    "print(f'Classes: {dataset.classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference and Testing\n",
    "Test the trained model on sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded class names from file: ['vanhau', 'vantoan']\n",
      "Model loaded successfully for inference.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load trained model for inference\n",
    "def load_trained_model(model_path, num_classes, device):\n",
    "    model = InceptionResnetV1(\n",
    "        classify=True,\n",
    "        pretrained='vggface2',\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Initialize MTCNN for inference\n",
    "mtcnn_inference = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Load class names with error handling\n",
    "class_names_path = 'class_names.txt'\n",
    "model_path = 'facenet_vantoan_vanhau.pth'\n",
    "\n",
    "try:\n",
    "    # Try to load class names from file\n",
    "    with open(class_names_path, 'r') as f:\n",
    "        class_names = [line.strip() for line in f.readlines()]\n",
    "    print(f\"Loaded class names from file: {class_names}\")\n",
    "except FileNotFoundError:\n",
    "    # Fallback: use current dataset classes\n",
    "    try:\n",
    "        class_names = dataset.classes\n",
    "        print(f\"Using current dataset classes: {class_names}\")\n",
    "    except NameError:\n",
    "        print(\"Error: No dataset or class names file found. Please run training first.\")\n",
    "        class_names = []\n",
    "\n",
    "# Load trained model with error handling\n",
    "if class_names and os.path.exists(model_path):\n",
    "    try:\n",
    "        model_inference = load_trained_model(model_path, len(class_names), device)\n",
    "        print(f\"Model loaded successfully for inference.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        model_inference = None\n",
    "else:\n",
    "    if not class_names:\n",
    "        print(\"Cannot load model: No class names available.\")\n",
    "    else:\n",
    "        print(f\"Cannot load model: Model file not found at {model_path}\")\n",
    "        print(\"Please run the training cells first to create the model.\")\n",
    "    model_inference = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. TODO 4: Understanding Softmax Function - Mathematical Formula\n",
    "\n",
    "**Softmax** is an activation function that converts raw logits into a probability distribution.\n",
    "\n",
    "#### Mathematical Formula:\n",
    "\n",
    "```\n",
    "For input vector z = [z‚ÇÅ, z‚ÇÇ, ..., z‚Çñ], the softmax function is:\n",
    "\n",
    "softmax(z·µ¢) = e^(z·µ¢) / Œ£(j=1 to k) e^(z‚±º)\n",
    "\n",
    "or in vector notation:\n",
    "softmax(z) = [e^(z‚ÇÅ)/S, e^(z‚ÇÇ)/S, ..., e^(z‚Çñ)/S]\n",
    "\n",
    "where S = Œ£(j=1 to k) e^(z‚±º) (normalization constant)\n",
    "```\n",
    "\n",
    "#### Mathematical Properties:\n",
    "\n",
    "1. **Exponential Transformation:**\n",
    "   ```\n",
    "   exp·µ¢ = e^(z·µ¢) for each element i\n",
    "   ```\n",
    "\n",
    "2. **Normalization:**\n",
    "   ```\n",
    "   S = Œ£(j=1 to k) e^(z‚±º) = e^(z‚ÇÅ) + e^(z‚ÇÇ) + ... + e^(z‚Çñ)\n",
    "   ```\n",
    "\n",
    "3. **Final Probabilities:**\n",
    "   ```\n",
    "   p·µ¢ = e^(z·µ¢) / S\n",
    "   ```\n",
    "\n",
    "#### Key Mathematical Properties:\n",
    "```\n",
    "1. Œ£(i=1 to k) softmax(z·µ¢) = 1  (probabilities sum to 1)\n",
    "2. softmax(z·µ¢) ‚àà (0, 1)         (all values between 0 and 1)\n",
    "3. softmax(z·µ¢ + c) = softmax(z·µ¢) (translation invariant)\n",
    "```\n",
    "\n",
    "#### Example Calculation:\n",
    "```\n",
    "Input: z = [1.0, 2.0, 3.0]\n",
    "\n",
    "Step 1: exp(z) = [e^1.0, e^2.0, e^3.0] = [2.718, 7.389, 20.086]\n",
    "\n",
    "Step 2: S = 2.718 + 7.389 + 20.086 = 30.193\n",
    "\n",
    "Step 3: softmax(z) = [2.718/30.193, 7.389/30.193, 20.086/30.193]\n",
    "                   = [0.090, 0.245, 0.665]\n",
    "\n",
    "Verification: 0.090 + 0.245 + 0.665 = 1.000 ‚úì\n",
    "```\n",
    "\n",
    "#### Why Softmax Works:\n",
    "- **Exponential** emphasizes larger values (winner-take-most)\n",
    "- **Normalization** ensures valid probability distribution\n",
    "- **Differentiable** for gradient-based optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_softmax(logits):\n",
    "    \"\"\"\n",
    "    TODO 4\n",
    "    Implement softmax function using basic math operations (for educational purposes)\n",
    "    \n",
    "    Args:\n",
    "        logits (torch.Tensor): Input tensor with shape [batch_size, num_classes]\n",
    "                              Contains raw model outputs (logits)\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Softmax probabilities with same shape as input\n",
    "                     Each row sums to 1.0, values between 0 and 1\n",
    "    \n",
    "    Mathematical Formula:\n",
    "        For each element logits[i][j]:\n",
    "        softmax[i][j] = exp(logits[i][j]) / sum(exp(logits[i][k]) for all k)\n",
    "    \n",
    "    Example:\n",
    "        Input:  logits = [[1.0, 2.0, 3.0]]  # 1 sample, 3 classes\n",
    "        Step 1: exp_values = [[2.718, 7.389, 20.086]]\n",
    "        Step 2: sum_exp = 2.718 + 7.389 + 20.086 = 30.193\n",
    "        Step 3: softmax = [[0.090, 0.245, 0.665]]  # probabilities sum to 1.0\n",
    "    \n",
    "    Your task:\n",
    "        1. Convert tensor to Python lists for easier manipulation\n",
    "        2. For each sample (row), calculate exponential of each logit\n",
    "        3. Sum all exponentials for that sample\n",
    "        4. Divide each exponential by the sum to get probabilities\n",
    "        5. Convert result back to tensor and return\n",
    "    \n",
    "    Hints:\n",
    "        - Use .tolist() to convert tensor to Python lists\n",
    "        - Use math.exp() to calculate exponential\n",
    "        - Use sum() to calculate sum of exponentials\n",
    "        - Use torch.tensor() to convert result back to tensor\n",
    "        - Process each row (sample) separately\n",
    "        - Make sure each row sums to approximately 1.0\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# def custom_softmax(logits):\n",
    "#     \"\"\"Implement softmax function using basic math operations\"\"\"\n",
    "#     import math\n",
    "    \n",
    "#     # Step 1: Convert tensor to Python lists\n",
    "#     logits_list = logits.tolist()\n",
    "    \n",
    "#     # Step 2: Calculate softmax for each sample\n",
    "#     softmax_result = []\n",
    "    \n",
    "#     for sample_logits in logits_list:  # For each sample (row)\n",
    "#         # Step 3: Calculate exponentials\n",
    "#         exp_values = []\n",
    "#         for logit in sample_logits:\n",
    "#             exp_values.append(math.exp(logit))\n",
    "        \n",
    "#         # Step 4: Calculate sum of exponentials\n",
    "#         sum_exp = sum(exp_values)\n",
    "        \n",
    "#         # Step 5: Calculate softmax probabilities\n",
    "#         softmax_row = []\n",
    "#         for exp_val in exp_values:\n",
    "#             probability = exp_val / sum_exp\n",
    "#             softmax_row.append(probability)\n",
    "        \n",
    "#         softmax_result.append(softmax_row)\n",
    "    \n",
    "#     # Step 6: Convert back to tensor\n",
    "#     return torch.tensor(softmax_result, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test our implemented function :v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing custom_softmax function...\n",
      "==================================================\n",
      "‚ùå Function custom_softmax() returns None - not implemented yet!\n",
      "Please implement the function according to the TODO instructions.\n"
     ]
    }
   ],
   "source": [
    "def test_custom_softmax():\n",
    "    \"\"\"Test function to verify custom_softmax implementation\"\"\"\n",
    "    print(\"Testing custom_softmax function...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if custom_softmax is implemented\n",
    "    try:\n",
    "        # Try a simple test first to see if function is implemented\n",
    "        test_logits = torch.tensor([[1.0, 2.0]], dtype=torch.float32)\n",
    "        test_result = custom_softmax(test_logits)\n",
    "        \n",
    "        # If we get here, function is implemented but might return None\n",
    "        if test_result is None:\n",
    "            print(\"‚ùå Function custom_softmax() returns None - not implemented yet!\")\n",
    "            print(\"Please implement the function according to the TODO instructions.\")\n",
    "            return\n",
    "            \n",
    "    except (NotImplementedError, TypeError, AttributeError):\n",
    "        print(\"‚ùå Function custom_softmax() is not implemented yet!\")\n",
    "        print(\"Please implement the function according to the TODO instructions.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in custom_softmax() implementation: {str(e)}\")\n",
    "        print(\"Please check your implementation and try again.\")\n",
    "        return\n",
    "    \n",
    "    print(\"‚úÖ Function custom_softmax() is implemented! Running tests...\")\n",
    "    print()\n",
    "    \n",
    "    # Test case 1: Simple 2-class case\n",
    "    logits_1 = torch.tensor([[1.0, 2.0]], dtype=torch.float32)\n",
    "    \n",
    "    try:\n",
    "        # Test your function\n",
    "        custom_result = custom_softmax(logits_1)\n",
    "        pytorch_result = torch.nn.functional.softmax(logits_1, dim=1)\n",
    "        \n",
    "        print(f\"Test Case 1 - Simple 2-class:\")\n",
    "        print(f\"Input logits: {logits_1.tolist()}\")\n",
    "        print(f\"Your result: {custom_result.tolist()}\")\n",
    "        print(f\"PyTorch result: {pytorch_result.tolist()}\")\n",
    "        \n",
    "        # Check if results are close\n",
    "        if custom_result is None:\n",
    "            print(f\"Status: ‚ùå FAIL - Function returns None\")\n",
    "        elif isinstance(custom_result, torch.Tensor):\n",
    "            # Check if values are close to PyTorch implementation\n",
    "            if torch.allclose(custom_result, pytorch_result, atol=0.001):\n",
    "                print(f\"Status: ‚úÖ PASS - Matches PyTorch softmax!\")\n",
    "            else:\n",
    "                print(f\"Status: ‚ùå FAIL - Results don't match PyTorch\")\n",
    "                \n",
    "            # Check if probabilities sum to 1\n",
    "            row_sum = custom_result.sum(dim=1).item()\n",
    "            print(f\"Row sum: {row_sum:.6f} (should be ~1.0)\")\n",
    "        else:\n",
    "            print(f\"Status: ‚ùå FAIL - Expected tensor, got {type(custom_result)}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Test Case 1 - Error: {str(e)}\")\n",
    "        print(\"‚ùå FAIL - Exception occurred during test\")\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "    # Test case 2: Multi-class, multi-sample\n",
    "    logits_2 = torch.tensor([\n",
    "        [1.0, 2.0, 3.0],     # Sample 1\n",
    "        [0.5, 1.5, 0.0]      # Sample 2\n",
    "    ], dtype=torch.float32)\n",
    "    \n",
    "    try:\n",
    "        custom_result_2 = custom_softmax(logits_2)\n",
    "        pytorch_result_2 = torch.nn.functional.softmax(logits_2, dim=1)\n",
    "        \n",
    "        print(f\"Test Case 2 - Multi-class, multi-sample:\")\n",
    "        print(f\"Input logits: {logits_2.tolist()}\")\n",
    "        print(f\"Your result: {custom_result_2.tolist()}\")\n",
    "        print(f\"PyTorch result: {pytorch_result_2.tolist()}\")\n",
    "        \n",
    "        # Check if results are close\n",
    "        if custom_result_2 is None:\n",
    "            print(f\"Status: ‚ùå FAIL - Function returns None\")\n",
    "        elif isinstance(custom_result_2, torch.Tensor):\n",
    "            if torch.allclose(custom_result_2, pytorch_result_2, atol=0.001):\n",
    "                print(f\"Status: ‚úÖ PASS - Matches PyTorch softmax!\")\n",
    "            else:\n",
    "                print(f\"Status: ‚ùå FAIL - Results don't match PyTorch\")\n",
    "                \n",
    "            # Check if each row sums to 1\n",
    "            row_sums = custom_result_2.sum(dim=1)\n",
    "            print(f\"Row sums: {row_sums.tolist()} (each should be ~1.0)\")\n",
    "        else:\n",
    "            print(f\"Status: ‚ùå FAIL - Expected tensor, got {type(custom_result_2)}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Test Case 2 - Error: {str(e)}\")\n",
    "        print(\"‚ùå FAIL - Exception occurred during test\")\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "    # Final comparison message\n",
    "    try:\n",
    "        if (custom_result is not None and custom_result_2 is not None and\n",
    "            torch.allclose(custom_result, pytorch_result, atol=0.001) and\n",
    "            torch.allclose(custom_result_2, pytorch_result_2, atol=0.001)):\n",
    "            print(\"üéâ Congratulations! Your softmax implementation is correct!\")\n",
    "            print(\"You can now use it in the predict_image function.\")\n",
    "        else:\n",
    "            print(\"‚ùå Implementation needs improvement. Please check the mathematical formula.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in final comparison: {str(e)}\")\n",
    "\n",
    "# Test the custom_softmax function\n",
    "test_custom_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing predict_image function...\n",
      "==================================================\n",
      "\n",
      "üéâ predict_image() function structure is correct!\n",
      "üí° To fully test this function, you need:\n",
      "   1. A trained model loaded\n",
      "   2. MTCNN initialized\n",
      "   3. Valid image files\n",
      "   4. Class names list\n",
      "\n",
      "Once training is complete, this function will be tested automatically.\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model, mtcnn, class_names, device):\n",
    "    \"\"\"Predict class of face in image\"\"\"\n",
    "    try:\n",
    "        # Step 1: Load and convert image to RGB\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Step 2: Use MTCNN to detect and crop face\n",
    "        img_cropped = mtcnn(img)\n",
    "        \n",
    "        # Step 3: Check if face was detected\n",
    "        if img_cropped is None:\n",
    "            return \"No face detected\", 0.0\n",
    "        \n",
    "        # Step 4: Preprocess for model input (add batch dimension and move to device)\n",
    "        img_cropped = img_cropped.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Step 5: Run inference with trained model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(img_cropped)\n",
    "            \n",
    "            # Step 6: Apply softmax to get probabilities\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Step 7: Find class with highest probability\n",
    "            confidence, predicted = torch.max(probabilities, 1)\n",
    "        \n",
    "        # Step 8: Get predicted class name and confidence score\n",
    "        predicted_class = class_names[predicted.item()]\n",
    "        confidence_score = confidence.item()\n",
    "        \n",
    "        return predicted_class, confidence_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Step 9: Handle exceptions gracefully\n",
    "        return f\"Error: {str(e)}\", 0.0\n",
    "\n",
    "\n",
    "def test_predict_image():\n",
    "    \"\"\"Test function to verify predict_image implementation\"\"\"\n",
    "    print(\"Testing predict_image function...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if predict_image is implemented\n",
    "    try:\n",
    "        # Create dummy inputs for testing\n",
    "        test_image_path = \"dummy_path.jpg\"  # This will cause an error, which is expected for testing\n",
    "        dummy_model = None\n",
    "        dummy_mtcnn = None\n",
    "        dummy_class_names = [\"class1\", \"class2\"]\n",
    "        dummy_device = torch.device('cpu')\n",
    "        \n",
    "        test_result = predict_image(test_image_path, dummy_model, dummy_mtcnn, dummy_class_names, dummy_device)\n",
    "        \n",
    "        # If we get here, function is implemented but might return None\n",
    "        if test_result is None:\n",
    "            print(\"‚ùå Function predict_image() returns None - not implemented yet!\")\n",
    "            print(\"Please implement the function according to the TODO instructions.\")\n",
    "            return\n",
    "        \n",
    "        # Check if it returns a tuple with 2 elements\n",
    "        if not isinstance(test_result, tuple) or len(test_result) != 2:\n",
    "            print(\"‚ùå Function should return a tuple with 2 elements: (predicted_class, confidence)\")\n",
    "            print(\"Please check your implementation.\")\n",
    "            return\n",
    "            \n",
    "    except (NotImplementedError, TypeError, AttributeError):\n",
    "        print(\"‚ùå Function predict_image() is not implemented yet!\")\n",
    "        print(\"Please implement the function according to the TODO instructions.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        # This is expected since we're using dummy inputs\n",
    "        if \"dummy_path.jpg\" in str(e) or \"NoneType\" in str(e):\n",
    "            print(\"‚úÖ Function predict_image() is implemented! (Error handling works correctly)\")\n",
    "            print(\"Function correctly handles invalid inputs and returns error messages.\")\n",
    "        else:\n",
    "            print(f\"‚ùå Unexpected error in predict_image() implementation: {str(e)}\")\n",
    "            print(\"Please check your implementation and try again.\")\n",
    "            return\n",
    "    \n",
    "    print(\"\\nüéâ predict_image() function structure is correct!\")\n",
    "    print(\"üí° To fully test this function, you need:\")\n",
    "    print(\"   1. A trained model loaded\")\n",
    "    print(\"   2. MTCNN initialized\") \n",
    "    print(\"   3. Valid image files\")\n",
    "    print(\"   4. Class names list\")\n",
    "    print(\"\\nOnce training is complete, this function will be tested automatically.\")\n",
    "\n",
    "# Test the predict_image function\n",
    "test_predict_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model on sample images...\n",
      "==================================================\n",
      "‚úÖ predict_image() function is implemented! Running tests...\n",
      "\n",
      "‚ùå vanhau -> vantoan (conf: 1.000)\n",
      "‚ùå vanhau -> vantoan (conf: 1.000)\n",
      "‚ùå vanhau -> vantoan (conf: 1.000)\n",
      "‚úÖ vantoan -> vantoan (conf: 1.000)\n",
      "‚úÖ vantoan -> vantoan (conf: 1.000)\n",
      "‚úÖ vantoan -> vantoan (conf: 1.000)\n",
      "\n",
      "Test Results: 3/6 correct (50.0%)\n"
     ]
    }
   ],
   "source": [
    "def test_sample_images():\n",
    "    \"\"\"Test model on sample images from both classes\"\"\"\n",
    "    # Check if predict_image function is implemented first\n",
    "    try:\n",
    "        # Test with dummy inputs to see if function is implemented\n",
    "        dummy_result = predict_image(\"dummy.jpg\", None, None, [\"test\"], torch.device('cpu'))\n",
    "        \n",
    "        # If we get here and result is None, function is not implemented\n",
    "        if dummy_result is None:\n",
    "            print(\"‚ùå Function predict_image() is not implemented yet!\")\n",
    "            print(\"Please implement the predict_image() function according to the TODO 3 instructions.\")\n",
    "            return []\n",
    "            \n",
    "    except (NotImplementedError, TypeError, AttributeError):\n",
    "        print(\"‚ùå Function predict_image() is not implemented yet!\")\n",
    "        print(\"Please implement the predict_image() function according to the TODO 3 instructions.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        # This is expected for dummy inputs - function is implemented\n",
    "        pass\n",
    "    \n",
    "    # Check if model and class names are available\n",
    "    if model_inference is None:\n",
    "        print(\"Error: Model not loaded. Cannot run inference.\")\n",
    "        return []\n",
    "    \n",
    "    if not class_names:\n",
    "        print(\"Error: No class names available.\")\n",
    "        return []\n",
    "    \n",
    "    print(\"‚úÖ predict_image() function is implemented! Running tests...\")\n",
    "    print()\n",
    "    \n",
    "    test_results = []\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        if os.path.exists(class_dir):\n",
    "            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            if not images:\n",
    "                print(f\"No images found in {class_dir}\")\n",
    "                continue\n",
    "            \n",
    "            # Test first few images from each class\n",
    "            for img_file in images[:3]:\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                predicted_class, confidence = predict_image(\n",
    "                    img_path, model_inference, mtcnn_inference, class_names, device\n",
    "                )\n",
    "                \n",
    "                result = {\n",
    "                    'true_class': class_name,\n",
    "                    'predicted_class': predicted_class,\n",
    "                    'confidence': confidence,\n",
    "                    'correct': predicted_class == class_name,\n",
    "                    'image_path': img_path\n",
    "                }\n",
    "                test_results.append(result)\n",
    "                \n",
    "                status = \"‚úÖ\" if result['correct'] else \"‚ùå\"\n",
    "                print(f\"{status} {class_name} -> {predicted_class} (conf: {confidence:.3f})\")\n",
    "        else:\n",
    "            print(f\"Directory not found: {class_dir}\")\n",
    "    \n",
    "    # Summary\n",
    "    if test_results:\n",
    "        correct_predictions = sum(1 for r in test_results if r['correct'])\n",
    "        accuracy = correct_predictions / len(test_results)\n",
    "        print(f\"\\nTest Results: {correct_predictions}/{len(test_results)} correct ({accuracy*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"No test results available.\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# Run tests with comprehensive error handling\n",
    "print(\"Testing model on sample images...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check all prerequisites\n",
    "if model_inference is not None and class_names:\n",
    "    test_results = test_sample_images()\n",
    "else:\n",
    "    print(\"Cannot run tests: Model or class names not available.\")\n",
    "    print(\"Please ensure training has completed successfully.\")\n",
    "    print()\n",
    "    \n",
    "    # Also check if predict_image is implemented\n",
    "    try:\n",
    "        dummy_result = predict_image(\"dummy.jpg\", None, None, [\"test\"], torch.device('cpu'))\n",
    "        if dummy_result is None:\n",
    "            print(\"Additionally: predict_image() function is not implemented.\")\n",
    "    except (NotImplementedError, TypeError, AttributeError):\n",
    "        print(\"Additionally: predict_image() function is not implemented.\")\n",
    "    except:\n",
    "        print(\"predict_image() function appears to be implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uit-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
